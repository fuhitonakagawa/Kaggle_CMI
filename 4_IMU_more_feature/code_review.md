# CMI BFRB Detection - Deep Learning Implementation ãƒ¬ãƒ“ãƒ¥ãƒ¼

## ğŸ“Š ç·åˆè©•ä¾¡
ã“ã®ã‚³ãƒ¼ãƒ‰ã¯ã€ãƒˆãƒƒãƒ—ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚¿ãƒ¼ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’å‚è€ƒã«ã—ãŸæ·±å±¤å­¦ç¿’ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®å®Ÿè£…ã‚’è©¦ã¿ã¦ã„ã¾ã™ãŒã€**é‡å¤§ãªå®Ÿè£…ãƒŸã‚¹ãŒã‚ã‚Šã¾ã™**ã€‚ã‚¿ã‚¤ãƒˆãƒ«ã¯ã€ŒDeep Learning with 1D-CNN + BiLSTM + Attentionã€ã¨ãªã£ã¦ã„ã¾ã™ãŒã€å®Ÿéš›ã«ã¯**LightGBMã®ã¿ã‚’ä½¿ç”¨**ã—ã¦ãŠã‚Šã€æ·±å±¤å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ãŒå…¨ãå®Ÿè£…ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚

## ğŸš¨ é‡å¤§ãªå•é¡Œç‚¹

### 1. **æ·±å±¤å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®å®Œå…¨ãªæ¬ å¦‚**
```python
# Line 565-566: LightGBMã‚’ä½¿ç”¨ï¼ˆæ·±å±¤å­¦ç¿’ã§ã¯ãªã„ï¼‰
binary_model = lgb.LGBMClassifier(**self.config["binary_lgbm"])
```
- ã‚¿ã‚¤ãƒˆãƒ«ã§è¬³ã£ã¦ã„ã‚‹ã€Œ1D-CNN + BiLSTM + Attentionã€ãŒ**ä¸€åˆ‡å®Ÿè£…ã•ã‚Œã¦ã„ãªã„**
- TensorFlowã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹ãŒã€å®Ÿéš›ã«ã¯ä½¿ç”¨ã—ã¦ã„ãªã„
- LightGBMã®è¨­å®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆ`binary_lgbm`, `bfrb_lgbm`, `non_bfrb_lgbm`ï¼‰ãŒå®šç¾©ã•ã‚Œã¦ã„ãªã„

### 2. **æœªå®šç¾©ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**
```python
# Line 565: lgbãŒæœªã‚¤ãƒ³ãƒãƒ¼ãƒˆ
binary_model = lgb.LGBMClassifier(**self.config["binary_lgbm"])

# Line 592-596: SMOTEãŒæœªã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from imblearn.over_sampling import SMOTE  # ã“ã‚ŒãŒå¿…è¦
```

### 3. **è¨­å®šã®ä¸æ•´åˆ**
```python
CONFIG = {
    # æ·±å±¤å­¦ç¿’ç”¨ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå®šç¾©ã•ã‚Œã¦ã„ã‚‹ãŒä½¿ç”¨ã•ã‚Œã¦ã„ãªã„
    "cnn_filters": [64, 128, 256],
    "lstm_units": 128,
    "gru_units": 128,
    "attention_units": 128,
    # LightGBMç”¨ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒæœªå®šç¾©
    # "binary_lgbm": {...},  # ã“ã‚ŒãŒå¿…è¦
    # "bfrb_lgbm": {...},    # ã“ã‚ŒãŒå¿…è¦
    # "non_bfrb_lgbm": {...}, # ã“ã‚ŒãŒå¿…è¦
}
```

## ğŸ”§ æ”¹å–„ãŒå¿…è¦ãªç‚¹

### 1. **æ·±å±¤å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®å®Ÿè£…**
å®Ÿéš›ã«CNN + BiLSTM + Attentionã‚’å®Ÿè£…ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼š

```python
def create_deep_model(input_shape, num_classes):
    inputs = tf.keras.Input(shape=input_shape)
    
    # 1D-CNN layers with residual connections
    x = tf.keras.layers.Conv1D(64, 3, padding='same', activation='relu')(inputs)
    x = tf.keras.layers.BatchNormalization()(x)
    x = tf.keras.layers.MaxPooling1D(2)(x)
    
    # BiLSTM layers
    x = tf.keras.layers.Bidirectional(
        tf.keras.layers.LSTM(128, return_sequences=True)
    )(x)
    
    # Attention mechanism
    attention = tf.keras.layers.MultiHeadAttention(
        num_heads=4, key_dim=32
    )(x, x)
    
    # Global pooling and dense layers
    x = tf.keras.layers.GlobalAveragePooling1D()(attention)
    x = tf.keras.layers.Dense(256, activation='relu')(x)
    x = tf.keras.layers.Dropout(0.4)(x)
    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)
    
    return tf.keras.Model(inputs, outputs)
```

### 2. **æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®é©åˆ‡ãªå‡¦ç†**
ç¾åœ¨ã¯çµ±è¨ˆçš„ç‰¹å¾´é‡ã‚’æŠ½å‡ºã—ã¦ã„ã¾ã™ãŒã€æ·±å±¤å­¦ç¿’ã§ã¯ç”Ÿã®æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã™ã¹ãã§ã™ï¼š

```python
def prepare_sequences(df, max_len=500):
    """æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°/ãƒˆãƒ©ãƒ³ã‚±ãƒ¼ãƒˆã—ã¦å›ºå®šé•·ã«ã™ã‚‹"""
    sequences = []
    for seq_id in df['sequence_id'].unique():
        seq_data = df[df['sequence_id'] == seq_id]
        imu_data = seq_data[['acc_x', 'acc_y', 'acc_z', 
                            'rot_w', 'rot_x', 'rot_y', 'rot_z']].values
        
        # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã¾ãŸã¯ãƒˆãƒ©ãƒ³ã‚±ãƒ¼ãƒˆ
        if len(imu_data) < max_len:
            padded = np.pad(imu_data, ((0, max_len - len(imu_data)), (0, 0)))
        else:
            padded = imu_data[:max_len]
        
        sequences.append(padded)
    
    return np.array(sequences)
```

### 3. **MixUp augmentationã®å®Ÿè£…**
ã‚³ãƒ¡ãƒ³ãƒˆã§MixUpã«è¨€åŠã—ã¦ã„ã¾ã™ãŒã€å®Ÿè£…ã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼š

```python
def mixup(x, y, alpha=0.4):
    """MixUp data augmentation"""
    batch_size = x.shape[0]
    indices = tf.random.shuffle(tf.range(batch_size))
    
    x_shuffled = tf.gather(x, indices)
    y_shuffled = tf.gather(y, indices)
    
    lambda_val = tfp.distributions.Beta(alpha, alpha).sample()
    
    x_mixed = lambda_val * x + (1 - lambda_val) * x_shuffled
    y_mixed = lambda_val * y + (1 - lambda_val) * y_shuffled
    
    return x_mixed, y_mixed
```

### 4. **Metal GPUå¯¾å¿œï¼ˆMacç”¨ï¼‰**
ç¾åœ¨ã®GPUè¨­å®šã¯NVIDIA GPUç”¨ã§ã™ã€‚Macå‘ã‘ã«Metal Performance Shadersã‚’ä½¿ç”¨ã™ã¹ãã§ã™ï¼š

```python
def configure_metal_gpu():
    """Configure Metal GPU for Mac"""
    # TensorFlowã®Metal pluginã‚’ä½¿ç”¨
    try:
        # M1/M2 Macã®å ´åˆã€tensorflow-metalãŒå¿…è¦
        physical_devices = tf.config.list_physical_devices('GPU')
        if physical_devices:
            print(f"âœ“ Metal GPU found: {physical_devices}")
            # ãƒ¡ãƒ¢ãƒªæˆé•·ã‚’æœ‰åŠ¹åŒ–
            for device in physical_devices:
                tf.config.experimental.set_memory_growth(device, True)
            return True
    except:
        print("âš ï¸ Metal GPU not available")
        return False
```

## ğŸ’¡ è‰¯ã„ç‚¹

### 1. **ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°**
- ä¸–ç•Œåº§æ¨™ç³»ã¸ã®å¤‰æ›
- è§’é€Ÿåº¦ãƒ»è§’è·é›¢ã®è¨ˆç®—
- åŒ…æ‹¬çš„ãªçµ±è¨ˆçš„ç‰¹å¾´é‡ã®æŠ½å‡º
- å‘¨æ³¢æ•°é ˜åŸŸã®ç‰¹å¾´é‡

### 2. **Two-Stageåˆ†é¡ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ**
- Binaryåˆ†é¡ã¨Multi-classåˆ†é¡ã®çµ„ã¿åˆã‚ã›ã¯è‰¯ã„ã‚¢ã‚¤ãƒ‡ã‚¢

### 3. **ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³**
- StratifiedGroupKFoldã®ä½¿ç”¨ã¯é©åˆ‡

## ğŸ“ æ¨å¥¨ã•ã‚Œã‚‹ä¿®æ­£æ‰‹é †

1. **ã¾ãšã€LightGBMãƒ™ãƒ¼ã‚¹ã®å®Ÿè£…ã¨ã—ã¦å®Œæˆã•ã›ã‚‹**
   - å¿…è¦ãªã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è¿½åŠ ï¼ˆlightgbm, imblearnï¼‰
   - LightGBMã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å®šç¾©
   - ç¾åœ¨ã®ã‚³ãƒ¼ãƒ‰ã‚’å‹•ä½œå¯èƒ½ã«ã™ã‚‹

2. **ãã®å¾Œã€æ·±å±¤å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’è¿½åŠ å®Ÿè£…**
   - CNN + BiLSTM + Attentionãƒ¢ãƒ‡ãƒ«ã®å®Ÿè£…
   - æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†
   - MixUpã®å®Ÿè£…
   - ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ‰‹æ³•ã®å®Ÿè£…

3. **Macç’°å¢ƒã¸ã®å¯¾å¿œ**
   - Metal GPUã®ã‚µãƒãƒ¼ãƒˆ
   - PyTorchã®å ´åˆã¯MPSãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚’ä½¿ç”¨

## ğŸ¯ ã‚¹ã‚³ã‚¢å‘ä¸Šã®ãŸã‚ã®ææ¡ˆ

1. **Temporal Convolutional Networks (TCN)ã®æ¤œè¨**
2. **Transformer-based architectureã®å°å…¥**
3. **Self-supervised pre-trainingã®æ´»ç”¨**
4. **Test Time Augmentation (TTA)ã®å®Ÿè£…**
5. **Pseudo-labelingã®æ´»ç”¨**

## çµè«–

ç¾åœ¨ã®ã‚³ãƒ¼ãƒ‰ã¯ã€æ·±å±¤å­¦ç¿’ã®å®Ÿè£…ã‚’è¬³ã„ãªãŒã‚‰å®Ÿéš›ã«ã¯LightGBMã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ã¨ã„ã†æ ¹æœ¬çš„ãªå•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚ã¾ãšã¯ã€ç¾åœ¨ã®LightGBMãƒ™ãƒ¼ã‚¹ã®å®Ÿè£…ã‚’å®Œæˆã•ã›ã¦ã‹ã‚‰ã€æ®µéšçš„ã«æ·±å±¤å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã¯å„ªã‚Œã¦ã„ã‚‹ã®ã§ã€ã“ã‚Œã‚’æ´»ã‹ã—ã¤ã¤ã€æ·±å±¤å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã¨ã®ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚’æ§‹ç¯‰ã™ã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šé«˜ã„ã‚¹ã‚³ã‚¢ãŒæœŸå¾…ã§ãã¾ã™ã€‚