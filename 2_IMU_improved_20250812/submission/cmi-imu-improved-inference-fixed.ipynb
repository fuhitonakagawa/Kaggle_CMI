{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ CMI BFRB Detection - IMU Improved Model Inference v2.0\n",
    "\n",
    "Fixed version for Kaggle submission with improved error handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import pickle\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "print('‚úì All imports loaded successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "MODEL_PATH = '/kaggle/input/cmi-imu-improved-models/'  # Update with your dataset name\n",
    "\n",
    "# Gesture mapping - MUST match training exactly\n",
    "GESTURE_MAPPER = {\n",
    "    'Above ear - pull hair': 0,\n",
    "    'Cheek - pinch skin': 1,\n",
    "    'Eyebrow - pull hair': 2,\n",
    "    'Eyelash - pull hair': 3,\n",
    "    'Forehead - pull hairline': 4,\n",
    "    'Forehead - scratch': 5,\n",
    "    'Neck - pinch skin': 6,\n",
    "    'Neck - scratch': 7,\n",
    "    'Drink from bottle/cup': 8,\n",
    "    'Feel around in tray and pull out an object': 9,\n",
    "    'Glasses on/off': 10,\n",
    "    'Pinch knee/leg skin': 11,\n",
    "    'Pull air toward your face': 12,\n",
    "    'Scratch knee/leg skin': 13,\n",
    "    'Text on phone': 14,\n",
    "    'Wave hello': 15,\n",
    "    'Write name in air': 16,\n",
    "    'Write name on leg': 17,\n",
    "}\n",
    "\n",
    "REVERSE_GESTURE_MAPPER = {v: k for k, v in GESTURE_MAPPER.items()}\n",
    "print(f'‚úì Configuration loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "print('Loading trained models...')\n",
    "\n",
    "try:\n",
    "    # Try to load the full model data\n",
    "    model_file = os.path.join(MODEL_PATH, 'imu_improved_model.pkl')\n",
    "    if os.path.exists(model_file):\n",
    "        with open(model_file, 'rb') as f:\n",
    "            model_data = pickle.load(f)\n",
    "        print('‚úì Loaded model data from imu_improved_model.pkl')\n",
    "    else:\n",
    "        # Try alternative file names\n",
    "        model_file = os.path.join(MODEL_PATH, 'model_data.pkl')\n",
    "        if os.path.exists(model_file):\n",
    "            with open(model_file, 'rb') as f:\n",
    "                model_data = pickle.load(f)\n",
    "            print('‚úì Loaded model data from model_data.pkl')\n",
    "        else:\n",
    "            # Load individual components\n",
    "            model_data = {}\n",
    "            \n",
    "            # Load LightGBM models\n",
    "            lgb_file = os.path.join(MODEL_PATH, 'lightgbm_models.pkl')\n",
    "            if os.path.exists(lgb_file):\n",
    "                with open(lgb_file, 'rb') as f:\n",
    "                    model_data['models'] = pickle.load(f)\n",
    "                print(f'‚úì Loaded {len(model_data[\"models\"])} LightGBM models')\n",
    "            \n",
    "            # Load feature columns\n",
    "            feat_file = os.path.join(MODEL_PATH, 'feature_columns.pkl')\n",
    "            if os.path.exists(feat_file):\n",
    "                with open(feat_file, 'rb') as f:\n",
    "                    model_data['feature_columns'] = pickle.load(f)\n",
    "                print(f'‚úì Loaded {len(model_data[\"feature_columns\"])} feature columns')\n",
    "            \n",
    "            # Load label encoder if available\n",
    "            le_file = os.path.join(MODEL_PATH, 'label_encoder.pkl')\n",
    "            if os.path.exists(le_file):\n",
    "                with open(le_file, 'rb') as f:\n",
    "                    model_data['label_encoder'] = pickle.load(f)\n",
    "    \n",
    "    # Extract components\n",
    "    models = model_data.get('models', [])\n",
    "    feature_cols = model_data.get('feature_columns', model_data.get('feature_names', []))\n",
    "    \n",
    "    print(f'‚úì Successfully loaded {len(models)} models')\n",
    "    print(f'‚úì Number of features: {len(feature_cols)}')\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f'Warning: Could not load models - {e}')\n",
    "    print('Will use fallback prediction')\n",
    "    models = []\n",
    "    feature_cols = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define simplified feature extraction\n",
    "def extract_features_simple(sequence_df, demographics_df=None):\n",
    "    \"\"\"Simplified feature extraction matching training.\"\"\"\n",
    "    \n",
    "    features = {}\n",
    "    \n",
    "    # Basic IMU columns\n",
    "    imu_cols = ['acc_x', 'acc_y', 'acc_z', 'rot_w', 'rot_x', 'rot_y', 'rot_z']\n",
    "    \n",
    "    # Sequence metadata\n",
    "    features['sequence_length'] = len(sequence_df)\n",
    "    \n",
    "    # Demographics (with defaults)\n",
    "    if demographics_df is not None and len(demographics_df) > 0:\n",
    "        demo_row = demographics_df.iloc[0]\n",
    "        features['age'] = demo_row.get('age', 30)\n",
    "        features['adult_child'] = demo_row.get('adult_child', 1)\n",
    "        features['sex'] = demo_row.get('sex', 0)\n",
    "        features['handedness'] = demo_row.get('handedness', 1)\n",
    "        features['height_cm'] = demo_row.get('height_cm', 170)\n",
    "        features['shoulder_to_wrist_cm'] = demo_row.get('shoulder_to_wrist_cm', 50)\n",
    "        features['elbow_to_wrist_cm'] = demo_row.get('elbow_to_wrist_cm', 30)\n",
    "    else:\n",
    "        features.update({\n",
    "            'age': 30, 'adult_child': 1, 'sex': 0, 'handedness': 1,\n",
    "            'height_cm': 170, 'shoulder_to_wrist_cm': 50, 'elbow_to_wrist_cm': 30\n",
    "        })\n",
    "    \n",
    "    # Extract statistical features for each IMU column\n",
    "    for col in imu_cols:\n",
    "        if col in sequence_df.columns:\n",
    "            data = sequence_df[col].fillna(0).values\n",
    "            \n",
    "            # Basic statistics\n",
    "            features[f'{col}_mean'] = np.mean(data)\n",
    "            features[f'{col}_std'] = np.std(data)\n",
    "            features[f'{col}_min'] = np.min(data)\n",
    "            features[f'{col}_max'] = np.max(data)\n",
    "            features[f'{col}_median'] = np.median(data)\n",
    "            features[f'{col}_q25'] = np.percentile(data, 25)\n",
    "            features[f'{col}_q75'] = np.percentile(data, 75)\n",
    "            features[f'{col}_iqr'] = features[f'{col}_q75'] - features[f'{col}_q25']\n",
    "            features[f'{col}_range'] = features[f'{col}_max'] - features[f'{col}_min']\n",
    "            \n",
    "            # Additional features\n",
    "            features[f'{col}_var'] = np.var(data)\n",
    "            features[f'{col}_first'] = data[0] if len(data) > 0 else 0\n",
    "            features[f'{col}_last'] = data[-1] if len(data) > 0 else 0\n",
    "            features[f'{col}_delta'] = features[f'{col}_last'] - features[f'{col}_first']\n",
    "            \n",
    "            # Segment features\n",
    "            seq_len = len(data)\n",
    "            if seq_len >= 9:\n",
    "                seg_size = seq_len // 3\n",
    "                seg1 = data[:seg_size]\n",
    "                seg2 = data[seg_size:2*seg_size]\n",
    "                seg3 = data[2*seg_size:]\n",
    "                \n",
    "                for i, seg in enumerate([seg1, seg2, seg3], 1):\n",
    "                    features[f'{col}_seg{i}_mean'] = np.mean(seg)\n",
    "                    features[f'{col}_seg{i}_std'] = np.std(seg)\n",
    "            else:\n",
    "                for i in range(1, 4):\n",
    "                    features[f'{col}_seg{i}_mean'] = features[f'{col}_mean']\n",
    "                    features[f'{col}_seg{i}_std'] = features[f'{col}_std']\n",
    "    \n",
    "    # Magnitude features\n",
    "    if all(col in sequence_df.columns for col in ['acc_x', 'acc_y', 'acc_z']):\n",
    "        acc_magnitude = np.sqrt(\n",
    "            sequence_df['acc_x'].fillna(0).values**2 + \n",
    "            sequence_df['acc_y'].fillna(0).values**2 + \n",
    "            sequence_df['acc_z'].fillna(0).values**2\n",
    "        )\n",
    "        \n",
    "        features['acc_magnitude_mean'] = np.mean(acc_magnitude)\n",
    "        features['acc_magnitude_std'] = np.std(acc_magnitude)\n",
    "        features['acc_magnitude_max'] = np.max(acc_magnitude)\n",
    "        features['acc_magnitude_min'] = np.min(acc_magnitude)\n",
    "    \n",
    "    return pd.DataFrame([features])\n",
    "\n",
    "print('‚úì Feature extraction function defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the main prediction function\n",
    "def predict(sequence: pl.DataFrame, demographics: pl.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Prediction function for CMI inference server.\n",
    "    Must return a string with the gesture name.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert to pandas\n",
    "        seq_df = sequence.to_pandas() if isinstance(sequence, pl.DataFrame) else sequence\n",
    "        demo_df = demographics.to_pandas() if isinstance(demographics, pl.DataFrame) else demographics\n",
    "        \n",
    "        # Check if we have models\n",
    "        if not models or not feature_cols:\n",
    "            # Return most common gesture as fallback\n",
    "            return 'Text on phone'\n",
    "        \n",
    "        # Extract features\n",
    "        features = extract_features_simple(seq_df, demo_df)\n",
    "        \n",
    "        # Ensure all required features are present\n",
    "        for col in feature_cols:\n",
    "            if col not in features.columns:\n",
    "                features[col] = 0\n",
    "        \n",
    "        # Select only the features used in training\n",
    "        X_pred = features[feature_cols]\n",
    "        \n",
    "        # Get predictions from all models\n",
    "        all_predictions = []\n",
    "        \n",
    "        for model in models:\n",
    "            try:\n",
    "                # Get prediction probabilities\n",
    "                if hasattr(model, 'predict_proba'):\n",
    "                    pred_proba = model.predict_proba(X_pred)\n",
    "                    pred_class = np.argmax(pred_proba[0])\n",
    "                else:\n",
    "                    # For models without predict_proba\n",
    "                    pred_class = model.predict(X_pred)[0]\n",
    "                \n",
    "                all_predictions.append(pred_class)\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        if all_predictions:\n",
    "            # Use majority vote\n",
    "            from collections import Counter\n",
    "            final_prediction = Counter(all_predictions).most_common(1)[0][0]\n",
    "        else:\n",
    "            # Fallback prediction\n",
    "            final_prediction = 14  # 'Text on phone'\n",
    "        \n",
    "        # Convert to gesture name\n",
    "        gesture_name = REVERSE_GESTURE_MAPPER.get(final_prediction, 'Text on phone')\n",
    "        \n",
    "        return gesture_name\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Always return a valid gesture name\n",
    "        return 'Text on phone'\n",
    "\n",
    "print('‚úì Prediction function defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the prediction function\n",
    "print('Testing prediction function...')\n",
    "\n",
    "# Create test data\n",
    "test_seq = pl.DataFrame({\n",
    "    'acc_x': np.random.randn(100),\n",
    "    'acc_y': np.random.randn(100),\n",
    "    'acc_z': np.random.randn(100),\n",
    "    'rot_w': np.random.randn(100),\n",
    "    'rot_x': np.random.randn(100),\n",
    "    'rot_y': np.random.randn(100),\n",
    "    'rot_z': np.random.randn(100)\n",
    "})\n",
    "\n",
    "test_demo = pl.DataFrame({\n",
    "    'age': [25],\n",
    "    'adult_child': [1],\n",
    "    'sex': [0],\n",
    "    'handedness': [1]\n",
    "})\n",
    "\n",
    "# Test prediction\n",
    "result = predict(test_seq, test_demo)\n",
    "print(f'Test result: {result}')\n",
    "print(f'Result type: {type(result)}')\n",
    "print(f'Is valid gesture: {result in GESTURE_MAPPER}')\n",
    "\n",
    "# Ensure result is a string\n",
    "assert isinstance(result, str), \"Prediction must return a string\"\n",
    "assert result in GESTURE_MAPPER, \"Prediction must be a valid gesture name\"\n",
    "\n",
    "print('‚úì Prediction function test passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CMI inference server\n",
    "import sys\n",
    "sys.path.append('/kaggle/input/cmi-detect-behavior-with-sensor-data')\n",
    "\n",
    "try:\n",
    "    import kaggle_evaluation.cmi_inference_server\n",
    "    print('‚úì CMI inference server imported successfully')\n",
    "except ImportError as e:\n",
    "    print(f'Error importing CMI inference server: {e}')\n",
    "    print('Make sure the competition data is added as input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize inference server\n",
    "print('Initializing inference server...')\n",
    "\n",
    "inference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict)\n",
    "\n",
    "print('‚úì Inference server initialized')\n",
    "print('‚úì Ready for predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference\n",
    "print('\\nStarting inference...')\n",
    "print('='*60)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    # Competition environment\n",
    "    print('üèÜ Running in competition environment')\n",
    "    print('Serving predictions...')\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    # Local testing\n",
    "    print('üß™ Running in local testing mode')\n",
    "    print('Processing test data...')\n",
    "    \n",
    "    try:\n",
    "        inference_server.run_local_gateway(\n",
    "            data_paths=(\n",
    "                '/kaggle/input/cmi-detect-behavior-with-sensor-data/test.csv',\n",
    "                '/kaggle/input/cmi-detect-behavior-with-sensor-data/test_demographics.csv',\n",
    "            )\n",
    "        )\n",
    "        print('\\n‚úÖ Inference completed successfully!')\n",
    "        print('‚úÖ submission.parquet has been generated')\n",
    "    except Exception as e:\n",
    "        print(f'\\n‚ö†Ô∏è Error during inference: {e}')\n",
    "        print('This may be normal in local testing.')\n",
    "        print('The submission file may still have been created.')\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('Process completed.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}