# CMI BFRB Detection - åŒ…æ‹¬çš„æ”¹å–„æˆ¦ç•¥ã¨å®Ÿè£…è¨ˆç”»
# Version: 1.0 - Comprehensive Analysis and Strategy
# Target Score: 0.85+ (Binary F1: 0.95+, Macro F1: 0.75+)

## ğŸ“Š ç¾çŠ¶åˆ†æ

### ç¾åœ¨ã®ã‚¹ã‚³ã‚¢
- **2_IMU_improved (LightGBM/XGBoost)**: 
  - Competition Score: 0.7094
  - Binary F1: 0.9459
  - Macro F1: 0.4730
  
- **4_IMU_more_feature (Deep Learning)**:
  - Competition Score: 0.6252
  - Binary F1: 0.9788
  - Macro F1: 0.2716

### å•é¡Œç‚¹ã®ç‰¹å®š
1. **æ·±å±¤å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ä½æ€§èƒ½**: Binary F1ã¯é«˜ã„ãŒMacro F1ãŒæ¥µç«¯ã«ä½ã„
2. **ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡ã¸ã®å¯¾å‡¦ä¸è¶³**: BFRBã‚¯ãƒ©ã‚¹é–“ã®åˆ†é¡ç²¾åº¦ãŒä½ã„
3. **ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æˆ¦ç•¥ã®æ¬ å¦‚**: å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã«ä¾å­˜
4. **æ¤œè¨¼æˆ¦ç•¥ã®å•é¡Œ**: Train-Test Split vs StratifiedGroupKFold

## ğŸ¯ æ”¹å–„æˆ¦ç•¥

### 1. ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã®æ”¹å–„

#### 1.1 ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å¼·åŒ–
```python
# æ—¢å­˜ã®ç‰¹å¾´é‡
- Linear Acceleration (é‡åŠ›é™¤å»æ¸ˆã¿)
- Angular Velocity (ã‚¯ã‚©ãƒ¼ã‚¿ãƒ‹ã‚ªãƒ³ã‹ã‚‰è¨ˆç®—)
- Magnitude features (åŠ é€Ÿåº¦ã€è§’é€Ÿåº¦)
- Jerk features (åŠ é€Ÿåº¦ã®å¾®åˆ†)

# æ–°è¦è¿½åŠ ç‰¹å¾´é‡
- Angular Distance (é€£ç¶šãƒ•ãƒ¬ãƒ¼ãƒ é–“ã®å›è»¢è§’åº¦)
- Frequency Domain Features (FFT, Welch PSD)
- Statistical Window Features (ç§»å‹•çª“çµ±è¨ˆé‡)
- Cross-axis Correlations (è»¸é–“ç›¸é–¢)
- Orientation-invariant Features (æ–¹å‘ä¸å¤‰ç‰¹å¾´é‡)
```

#### 1.2 TOF/Thermalç‰¹å¾´é‡ã®æ”¹å–„
```python
# æ—¢å­˜: å˜ç´”ãªçµ±è¨ˆé‡ã®ã¿
# æ”¹å–„æ¡ˆ:
- Spatial Pattern Recognition (ç©ºé–“ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜)
- Temporal Dynamics (æ™‚é–“çš„å¤‰åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³)
- Multi-scale Aggregation (ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«é›†ç´„)
- Anomaly Detection Features (ç•°å¸¸æ¤œçŸ¥ç‰¹å¾´é‡)
```

### 2. ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æ”¹å–„

#### 2.1 ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Hybrid Model Architecture       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ Deep Branch  â”‚  â”‚ GBDT Branch  â”‚â”‚
â”‚  â”‚  (CNN+RNN)   â”‚  â”‚ (LightGBM)   â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚         â”‚                  â”‚        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚    Meta-Learner (Stacking)     â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 2.2 æ·±å±¤å­¦ç¿’ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æ”¹å–„
```python
# Multi-Head Architecture
- Head 1: Binary Classification (BFRB vs Non-BFRB)
- Head 2: BFRB Type Classification (8 classes)
- Head 3: Full Classification (18 classes)

# Improved Components:
- Multi-Scale CNN (ç•°ãªã‚‹ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚º)
- Transformer Encoder layers
- Temporal Convolutional Network (TCN)
- Gated Recurrent Units with Skip Connections
```

### 3. è¨“ç·´æˆ¦ç•¥ã®æ”¹å–„

#### 3.1 éšå±¤çš„å­¦ç¿’
```python
# Stage 1: Binary Classification
- BFRB vs Non-BFRB ã®é«˜ç²¾åº¦åˆ†é¡å™¨ã‚’è¨“ç·´
- Class weight: {0: 1.0, 1: 2.0}

# Stage 2: BFRB Subtype Classification
- BFRBã‚µãƒ³ãƒ—ãƒ«ã®ã¿ã§8ã‚¯ãƒ©ã‚¹åˆ†é¡å™¨ã‚’è¨“ç·´
- Focal Loss for handling class imbalance

# Stage 3: End-to-End Fine-tuning
- å…¨ä½“ã‚’é€šã—ãŸæœ€é©åŒ–
- Custom loss: Î± * Binary_CE + Î² * Macro_CE
```

#### 3.2 ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µæˆ¦ç•¥
```python
# Time Series Augmentation
- MixUp (Î±=0.4)
- CutMix for sequences
- Time Warping
- Magnitude Warping
- Random Noise Injection
- Rotation Augmentation (for IMU)
```

### 4. ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æˆ¦ç•¥

#### 4.1 ãƒ¢ãƒ‡ãƒ«å¤šæ§˜æ€§ã®ç¢ºä¿
```python
models = [
    # Deep Learning Models
    "CNN_BiLSTM_Attention",     # Base architecture
    "TCN_Transformer",           # Alternative architecture
    "ResNet1D_GRU",             # Residual architecture
    
    # Gradient Boosting Models
    "LightGBM_IMU_only",        # IMU features only
    "LightGBM_Full",            # All features
    "XGBoost_Engineered",       # Advanced features
    "CatBoost_Categorical",     # With categorical encoding
]
```

#### 4.2 é‡ã¿ä»˜ã‘æˆ¦ç•¥
```python
# Validation-based Weighting
- Binary F1 score weight: 0.5
- Macro F1 score weight: 0.5
- Dynamic weighting based on confidence

# Blending Methods:
1. Simple Average
2. Weighted Average (validation scores)
3. Rank Average
4. Meta-learner Stacking
```

### 5. æ¤œè¨¼æˆ¦ç•¥

#### 5.1 StratifiedGroupKFold
```python
# 5-Fold Cross Validation
- Group by subject_id (no subject leakage)
- Stratify by gesture class
- Maintain class distribution
```

#### 5.2 è©•ä¾¡æŒ‡æ¨™ã®æœ€é©åŒ–
```python
def custom_metric(y_true, y_pred):
    # Binary F1 (BFRB detection)
    binary_f1 = f1_score(y_true < 8, y_pred < 8)
    
    # Macro F1 (BFRB classification)
    bfrb_mask = y_true < 8
    if bfrb_mask.any():
        macro_f1 = f1_score(
            y_true[bfrb_mask],
            y_pred[bfrb_mask],
            average='macro'
        )
    else:
        macro_f1 = 0
    
    # Competition metric
    return (binary_f1 + macro_f1) / 2
```

## ğŸ“‹ å®Ÿè£…å„ªå…ˆé †ä½

### Phase 1: åŸºç›¤å¼·åŒ–ï¼ˆ1-2æ—¥ï¼‰
1. âœ… StratifiedGroupKFoldæ¤œè¨¼ã®å®Ÿè£…
2. âœ… æ‹¡å¼µç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
3. âœ… ãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ–ã¨ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã®æ”¹å–„

### Phase 2: ãƒ¢ãƒ‡ãƒ«é–‹ç™ºï¼ˆ2-3æ—¥ï¼‰
1. â¬œ éšå±¤çš„åˆ†é¡å™¨ã®å®Ÿè£…
2. â¬œ æ”¹å–„ã•ã‚ŒãŸæ·±å±¤å­¦ç¿’ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
3. â¬œ LightGBM/XGBoostã®æœ€é©åŒ–

### Phase 3: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼ˆ1æ—¥ï¼‰
1. â¬œ è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
2. â¬œ æœ€é©ãªé‡ã¿ä»˜ã‘ã®æ¢ç´¢
3. â¬œ ãƒ¡ã‚¿å­¦ç¿’å™¨ã®å®Ÿè£…

### Phase 4: æœ€çµ‚èª¿æ•´ï¼ˆ1æ—¥ï¼‰
1. â¬œ ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–
2. â¬œ é–¾å€¤èª¿æ•´
3. â¬œ æ¨è«–é€Ÿåº¦ã®æœ€é©åŒ–

## ğŸ¯ æœŸå¾…ã•ã‚Œã‚‹æ”¹å–„

### ã‚¹ã‚³ã‚¢ç›®æ¨™
- **Binary F1**: 0.95+ (ç¾åœ¨: 0.9459)
- **Macro F1**: 0.75+ (ç¾åœ¨: 0.4730)
- **Combined Score**: 0.85+ (ç¾åœ¨: 0.7094)

### ä¸»è¦ãªæ”¹å–„ãƒã‚¤ãƒ³ãƒˆ
1. **Macro F1ã®å¤§å¹…æ”¹å–„**: éšå±¤çš„å­¦ç¿’ã¨ã‚¯ãƒ©ã‚¹ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°
2. **å®‰å®šæ€§ã®å‘ä¸Š**: StratifiedGroupKFoldã«ã‚ˆã‚‹é©åˆ‡ãªæ¤œè¨¼
3. **æ±åŒ–æ€§èƒ½**: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã«ã‚ˆã‚‹ãƒ­ãƒã‚¹ãƒˆæ€§å‘ä¸Š

## ğŸ”§ æŠ€è¡“çš„è€ƒæ…®äº‹é …

### GPUæœ€é©åŒ–
- Metal GPU (M1/M2 Mac) ã‚µãƒãƒ¼ãƒˆ
- Mixed Precision Training (å¯èƒ½ãªå ´åˆ)
- ãƒãƒƒãƒã‚µã‚¤ã‚ºã®æœ€é©åŒ–

### ãƒ¡ãƒ¢ãƒªç®¡ç†
- ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·ã®å‹•çš„ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
- ãƒ‡ãƒ¼ã‚¿ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã®ä½¿ç”¨
- åŠ¹ç‡çš„ãªç‰¹å¾´é‡è¨ˆç®—

### æ¨è«–æœ€é©åŒ–
- ãƒ¢ãƒ‡ãƒ«é‡å­åŒ–
- ãƒãƒƒãƒæ¨è«–
- ç‰¹å¾´é‡ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°

## ğŸ“ å®Ÿè£…ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

### ãƒ‡ãƒ¼ã‚¿å‡¦ç†
- [ ] é‡åŠ›é™¤å»ã®å®Ÿè£…ç¢ºèª
- [ ] è§’é€Ÿåº¦è¨ˆç®—ã®å®Ÿè£…ç¢ºèª
- [ ] FFTç‰¹å¾´é‡ã®è¿½åŠ 
- [ ] çª“é–¢æ•°çµ±è¨ˆé‡ã®è¿½åŠ 

### ãƒ¢ãƒ‡ãƒ«å®Ÿè£…
- [ ] Two-branch architectureã®å®Ÿè£…
- [ ] Attention mechanismã®å®Ÿè£…
- [ ] éšå±¤çš„åˆ†é¡å™¨ã®å®Ÿè£…
- [ ] LightGBMãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®æœ€é©åŒ–

### è¨“ç·´ãƒ—ãƒ­ã‚»ã‚¹
- [ ] StratifiedGroupKFoldã®å®Ÿè£…
- [ ] ã‚«ã‚¹ã‚¿ãƒ æå¤±é–¢æ•°ã®å®Ÿè£…
- [ ] Early Stoppingã®è¨­å®š
- [ ] Learning Rate Schedulingã®å®Ÿè£…

### è©•ä¾¡ã¨æå‡º
- [ ] ãƒ­ãƒ¼ã‚«ãƒ«è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
- [ ] Kaggle APIçµ±åˆ
- [ ] ã‚µãƒ–ãƒŸãƒƒã‚·ãƒ§ãƒ³ç”Ÿæˆ
- [ ] ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

## ğŸš€ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

1. **immediate**: åŸºæœ¬çš„ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®å®Ÿè£…
2. **next**: éšå±¤çš„åˆ†é¡å™¨ã®é–‹ç™º
3. **future**: ãƒ•ãƒ«ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã®æ§‹ç¯‰

---

**Note**: ã“ã®æˆ¦ç•¥ã¯ã€æ—¢å­˜ã®å®Ÿè£…ã¨Kaggleã®ä¸Šä½ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã®åˆ†æã«åŸºã¥ã„ã¦ã„ã¾ã™ã€‚
å®Ÿè£…æ™‚ã«ã¯ã€å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’æ®µéšçš„ã«ãƒ†ã‚¹ãƒˆã—ã€æ”¹å–„ã‚’ç¢ºèªã—ãªãŒã‚‰é€²ã‚ã‚‹ã“ã¨ãŒé‡è¦ã§ã™ã€‚