{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMI BFRB Detection - IMU-only LightGBM Inference\n",
    "\n",
    "This notebook performs inference using the trained IMU-only LightGBM model and generates submission.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "# Import the CMI inference server\n",
    "sys.path.append('/kaggle/input/cmi-detect-behavior-with-sensor-data')\n",
    "import kaggle_evaluation.cmi_inference_server\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "print('✓ All imports loaded successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "print('Loading trained model...')\n",
    "model_path = '/kaggle/input/imu-lgbm-model/imu_lgbm_model.pkl'  # Update this path based on where your model is saved\n",
    "model_data = joblib.load(model_path)\n",
    "\n",
    "models = model_data['models']\n",
    "feature_names = model_data['feature_names']\n",
    "reverse_gesture_mapper = model_data['reverse_gesture_mapper']\n",
    "config = model_data['config']\n",
    "\n",
    "print(f'✓ Loaded {len(models)} models')\n",
    "print(f'✓ Number of features: {len(feature_names)}')\n",
    "print(f'✓ CV Score: {model_data[\"mean_cv_score\"]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature extraction functions (same as training)\n",
    "ACC_COLS = ['acc_x', 'acc_y', 'acc_z']\n",
    "ROT_COLS = ['rot_w', 'rot_x', 'rot_y', 'rot_z']\n",
    "\n",
    "def handle_quaternion_missing_values(rot_data: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Handle missing values in quaternion data.\"\"\"\n",
    "    rot_cleaned = rot_data.copy()\n",
    "    \n",
    "    for i in range(len(rot_data)):\n",
    "        row = rot_data[i]\n",
    "        missing_count = np.isnan(row).sum()\n",
    "        \n",
    "        if missing_count == 0:\n",
    "            norm = np.linalg.norm(row)\n",
    "            if norm > 1e-8:\n",
    "                rot_cleaned[i] = row / norm\n",
    "            else:\n",
    "                rot_cleaned[i] = [1.0, 0.0, 0.0, 0.0]\n",
    "        elif missing_count == 1:\n",
    "            missing_idx = np.where(np.isnan(row))[0][0]\n",
    "            valid_values = row[~np.isnan(row)]\n",
    "            sum_squares = np.sum(valid_values**2)\n",
    "            if sum_squares <= 1.0:\n",
    "                missing_value = np.sqrt(max(0, 1.0 - sum_squares))\n",
    "                if i > 0 and not np.isnan(rot_cleaned[i-1, missing_idx]):\n",
    "                    if rot_cleaned[i-1, missing_idx] < 0:\n",
    "                        missing_value = -missing_value\n",
    "                rot_cleaned[i, missing_idx] = missing_value\n",
    "                rot_cleaned[i, ~np.isnan(row)] = valid_values\n",
    "            else:\n",
    "                rot_cleaned[i] = [1.0, 0.0, 0.0, 0.0]\n",
    "        else:\n",
    "            rot_cleaned[i] = [1.0, 0.0, 0.0, 0.0]\n",
    "    \n",
    "    return rot_cleaned\n",
    "\n",
    "def compute_world_acceleration(acc: np.ndarray, rot: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Convert acceleration from device to world coordinates.\"\"\"\n",
    "    try:\n",
    "        rot_scipy = rot[:, [1, 2, 3, 0]]  # Convert to scipy format\n",
    "        norms = np.linalg.norm(rot_scipy, axis=1)\n",
    "        if np.any(norms < 1e-8):\n",
    "            mask = norms < 1e-8\n",
    "            rot_scipy[mask] = [0.0, 0.0, 0.0, 1.0]\n",
    "        r = R.from_quat(rot_scipy)\n",
    "        acc_world = r.apply(acc)\n",
    "    except Exception:\n",
    "        acc_world = acc.copy()\n",
    "    return acc_world\n",
    "\n",
    "print('✓ Helper functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_statistical_features(data: np.ndarray, prefix: str) -> dict:\n",
    "    \"\"\"Extract statistical features from 1D time series.\"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # Basic statistics\n",
    "    features[f'{prefix}_mean'] = np.mean(data)\n",
    "    features[f'{prefix}_std'] = np.std(data)\n",
    "    features[f'{prefix}_var'] = np.var(data)\n",
    "    features[f'{prefix}_min'] = np.min(data)\n",
    "    features[f'{prefix}_max'] = np.max(data)\n",
    "    features[f'{prefix}_median'] = np.median(data)\n",
    "    features[f'{prefix}_q25'] = np.percentile(data, 25)\n",
    "    features[f'{prefix}_q75'] = np.percentile(data, 75)\n",
    "    features[f'{prefix}_iqr'] = features[f'{prefix}_q75'] - features[f'{prefix}_q25']\n",
    "    features[f'{prefix}_range'] = features[f'{prefix}_max'] - features[f'{prefix}_min']\n",
    "    \n",
    "    # Boundary features\n",
    "    features[f'{prefix}_first'] = data[0] if len(data) > 0 else 0\n",
    "    features[f'{prefix}_last'] = data[-1] if len(data) > 0 else 0\n",
    "    features[f'{prefix}_delta'] = features[f'{prefix}_last'] - features[f'{prefix}_first']\n",
    "    \n",
    "    # Higher order moments\n",
    "    if len(data) > 1 and np.std(data) > 1e-8:\n",
    "        features[f'{prefix}_skew'] = pd.Series(data).skew()\n",
    "        features[f'{prefix}_kurt'] = pd.Series(data).kurtosis()\n",
    "    else:\n",
    "        features[f'{prefix}_skew'] = 0\n",
    "        features[f'{prefix}_kurt'] = 0\n",
    "    \n",
    "    # Differential features\n",
    "    if len(data) > 1:\n",
    "        diff_data = np.diff(data)\n",
    "        features[f'{prefix}_diff_mean'] = np.mean(diff_data)\n",
    "        features[f'{prefix}_diff_std'] = np.std(diff_data)\n",
    "        features[f'{prefix}_n_changes'] = np.sum(np.abs(diff_data) > np.std(data) * 0.1)\n",
    "    else:\n",
    "        features[f'{prefix}_diff_mean'] = 0\n",
    "        features[f'{prefix}_diff_std'] = 0\n",
    "        features[f'{prefix}_n_changes'] = 0\n",
    "    \n",
    "    # Segment features (3 segments)\n",
    "    seq_len = len(data)\n",
    "    if seq_len >= 9:\n",
    "        seg_size = seq_len // 3\n",
    "        for i in range(3):\n",
    "            start_idx = i * seg_size\n",
    "            end_idx = (i + 1) * seg_size if i < 2 else seq_len\n",
    "            segment = data[start_idx:end_idx]\n",
    "            features[f'{prefix}_seg{i+1}_mean'] = np.mean(segment)\n",
    "            features[f'{prefix}_seg{i+1}_std'] = np.std(segment)\n",
    "        # Segment transitions\n",
    "        features[f'{prefix}_seg1_to_seg2'] = features[f'{prefix}_seg2_mean'] - features[f'{prefix}_seg1_mean']\n",
    "        features[f'{prefix}_seg2_to_seg3'] = features[f'{prefix}_seg3_mean'] - features[f'{prefix}_seg2_mean']\n",
    "    else:\n",
    "        for i in range(3):\n",
    "            features[f'{prefix}_seg{i+1}_mean'] = features[f'{prefix}_mean']\n",
    "            features[f'{prefix}_seg{i+1}_std'] = features[f'{prefix}_std']\n",
    "        features[f'{prefix}_seg1_to_seg2'] = 0\n",
    "        features[f'{prefix}_seg2_to_seg3'] = 0\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(sequence: pl.DataFrame, demographics: pl.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Extract features from IMU sequence.\"\"\"\n",
    "    # Convert to pandas\n",
    "    seq_df = sequence.to_pandas()\n",
    "    demo_df = demographics.to_pandas()\n",
    "    \n",
    "    # Get available columns\n",
    "    available_acc_cols = [col for col in ACC_COLS if col in seq_df.columns]\n",
    "    available_rot_cols = [col for col in ROT_COLS if col in seq_df.columns]\n",
    "    \n",
    "    # Handle missing values\n",
    "    acc_data = seq_df[available_acc_cols].copy()\n",
    "    acc_data = acc_data.ffill().bfill().fillna(0)\n",
    "    \n",
    "    rot_data = seq_df[available_rot_cols].copy()\n",
    "    rot_data = rot_data.ffill().bfill()\n",
    "    \n",
    "    # Handle quaternion missing values\n",
    "    rot_data_clean = handle_quaternion_missing_values(rot_data.values)\n",
    "    \n",
    "    # Compute world acceleration\n",
    "    world_acc_data = compute_world_acceleration(acc_data.values, rot_data_clean)\n",
    "    \n",
    "    # Initialize features\n",
    "    features = {}\n",
    "    \n",
    "    # Sequence metadata\n",
    "    features['sequence_length'] = len(seq_df)\n",
    "    \n",
    "    # Demographics features\n",
    "    if len(demo_df) > 0:\n",
    "        demo_row = demo_df.iloc[0]\n",
    "        features['age'] = demo_row.get('age', 0)\n",
    "        features['adult_child'] = demo_row.get('adult_child', 0)\n",
    "        features['sex'] = demo_row.get('sex', 0)\n",
    "        features['handedness'] = demo_row.get('handedness', 0)\n",
    "        features['height_cm'] = demo_row.get('height_cm', 0)\n",
    "        features['shoulder_to_wrist_cm'] = demo_row.get('shoulder_to_wrist_cm', 0)\n",
    "        features['elbow_to_wrist_cm'] = demo_row.get('elbow_to_wrist_cm', 0)\n",
    "    else:\n",
    "        # Default values if demographics not available\n",
    "        features['age'] = 0\n",
    "        features['adult_child'] = 0\n",
    "        features['sex'] = 0\n",
    "        features['handedness'] = 0\n",
    "        features['height_cm'] = 0\n",
    "        features['shoulder_to_wrist_cm'] = 0\n",
    "        features['elbow_to_wrist_cm'] = 0\n",
    "    \n",
    "    # Extract statistical features for each axis\n",
    "    for i, axis in enumerate(['x', 'y', 'z']):\n",
    "        if i < acc_data.shape[1]:\n",
    "            # Device acceleration\n",
    "            features.update(extract_statistical_features(acc_data.values[:, i], f'acc_{axis}'))\n",
    "            # World acceleration\n",
    "            features.update(extract_statistical_features(world_acc_data[:, i], f'world_acc_{axis}'))\n",
    "    \n",
    "    # Rotation features\n",
    "    for i, comp in enumerate(['w', 'x', 'y', 'z']):\n",
    "        if i < rot_data_clean.shape[1]:\n",
    "            features.update(extract_statistical_features(rot_data_clean[:, i], f'rot_{comp}'))\n",
    "    \n",
    "    # Magnitude features\n",
    "    acc_magnitude = np.linalg.norm(acc_data.values, axis=1)\n",
    "    world_acc_magnitude = np.linalg.norm(world_acc_data, axis=1)\n",
    "    \n",
    "    features.update(extract_statistical_features(acc_magnitude, 'acc_magnitude'))\n",
    "    features.update(extract_statistical_features(world_acc_magnitude, 'world_acc_magnitude'))\n",
    "    \n",
    "    # Difference between device and world acceleration\n",
    "    acc_world_diff = acc_magnitude - world_acc_magnitude\n",
    "    features.update(extract_statistical_features(acc_world_diff, 'acc_world_diff'))\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    result_df = pd.DataFrame([features])\n",
    "    \n",
    "    # Ensure all expected features are present\n",
    "    for col in feature_names:\n",
    "        if col not in result_df.columns:\n",
    "            result_df[col] = 0\n",
    "    \n",
    "    # Select only the features used in training\n",
    "    result_df = result_df[feature_names]\n",
    "    result_df = result_df.fillna(0)\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "print('✓ Feature extraction function defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prediction function for CMI inference server\n",
    "def predict(sequence: pl.DataFrame, demographics: pl.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Prediction function for CMI inference server.\n",
    "    Takes a single sequence and returns the predicted gesture name.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract features\n",
    "        features = extract_features(sequence, demographics)\n",
    "        \n",
    "        # Get predictions from all models\n",
    "        predictions = []\n",
    "        probabilities = []\n",
    "        \n",
    "        for model in models:\n",
    "            # Get prediction probabilities\n",
    "            pred_proba = model.predict_proba(features)\n",
    "            probabilities.append(pred_proba[0])\n",
    "            \n",
    "            # Get predicted class\n",
    "            pred_class = np.argmax(pred_proba, axis=1)[0]\n",
    "            predictions.append(pred_class)\n",
    "        \n",
    "        # Ensemble: average probabilities\n",
    "        avg_proba = np.mean(probabilities, axis=0)\n",
    "        final_prediction = np.argmax(avg_proba)\n",
    "        \n",
    "        # Convert to gesture name\n",
    "        gesture_name = reverse_gesture_mapper[final_prediction]\n",
    "        \n",
    "        return gesture_name\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Prediction error: {e}\")\n",
    "        # Return default prediction in case of error\n",
    "        return 'Text on phone'\n",
    "\n",
    "print('✓ Prediction function defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the prediction function with a small example\n",
    "print('Testing prediction function...')\n",
    "\n",
    "# Create dummy data for testing\n",
    "test_sequence = pl.DataFrame({\n",
    "    'acc_x': np.random.randn(100),\n",
    "    'acc_y': np.random.randn(100),\n",
    "    'acc_z': np.random.randn(100),\n",
    "    'rot_w': np.random.randn(100),\n",
    "    'rot_x': np.random.randn(100),\n",
    "    'rot_y': np.random.randn(100),\n",
    "    'rot_z': np.random.randn(100)\n",
    "})\n",
    "\n",
    "test_demographics = pl.DataFrame({\n",
    "    'age': [25],\n",
    "    'adult_child': [1],\n",
    "    'sex': [0],\n",
    "    'handedness': [1],\n",
    "    'height_cm': [175],\n",
    "    'shoulder_to_wrist_cm': [50],\n",
    "    'elbow_to_wrist_cm': [30]\n",
    "})\n",
    "\n",
    "# Test prediction\n",
    "test_result = predict(test_sequence, test_demographics)\n",
    "print(f'✓ Test prediction: {test_result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CMI inference server\n",
    "print('Initializing CMI inference server...')\n",
    "\n",
    "inference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict)\n",
    "\n",
    "print('✓ Inference server initialized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference based on environment\n",
    "print('Starting inference...')\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    # Competition environment: serve predictions\n",
    "    print('Running in competition environment...')\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    # Local testing: run on test data\n",
    "    print('Running in local testing mode...')\n",
    "    inference_server.run_local_gateway(\n",
    "        data_paths=(\n",
    "            '/kaggle/input/cmi-detect-behavior-with-sensor-data/test.csv',\n",
    "            '/kaggle/input/cmi-detect-behavior-with-sensor-data/test_demographics.csv',\n",
    "        )\n",
    "    )\n",
    "    print('\\n✓ Inference complete!')\n",
    "    print('✓ submission.parquet has been generated')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}