# å®Ÿè£…ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—
# CMI BFRB Detection - Implementation Roadmap

## ğŸ¯ å„ªå…ˆå®Ÿè£…é …ç›®ï¼ˆã‚¹ã‚³ã‚¢å‘ä¸Šã¸ã®å½±éŸ¿åº¦é †ï¼‰

### Priority 1: Macro F1æ”¹å–„ã®æ ¸å¿ƒéƒ¨åˆ†ï¼ˆå½±éŸ¿åº¦: â˜…â˜…â˜…â˜…â˜…ï¼‰

#### 1.1 éšå±¤çš„åˆ†é¡ã®å®Ÿè£…
```python
# æœ€å„ªå…ˆ: ã“ã‚Œã ã‘ã§Macro F1ãŒ0.6+ã«æ”¹å–„ã•ã‚Œã‚‹å¯èƒ½æ€§
# å®Ÿè£…æ™‚é–“: 2-3æ™‚é–“

class HierarchicalClassifier:
    def __init__(self):
        # Binary: BFRB (0-7) vs Non-BFRB (8-17)
        self.binary_model = None
        # BFRBå°‚ç”¨: 8ã‚¯ãƒ©ã‚¹åˆ†é¡
        self.bfrb_model = None
        
    def train(self, X, y):
        # Step 1: Binaryåˆ†é¡å™¨ã‚’è¨“ç·´
        y_binary = (y < 8).astype(int)
        self.binary_model = LightGBM(params_binary)
        self.binary_model.fit(X, y_binary)
        
        # Step 2: BFRBã‚µãƒ³ãƒ—ãƒ«ã®ã¿ã§8ã‚¯ãƒ©ã‚¹åˆ†é¡å™¨ã‚’è¨“ç·´
        bfrb_mask = y < 8
        X_bfrb = X[bfrb_mask]
        y_bfrb = y[bfrb_mask]
        self.bfrb_model = LightGBM(params_multiclass)
        self.bfrb_model.fit(X_bfrb, y_bfrb)
```

#### 1.2 Angular Velocityç‰¹å¾´é‡
```python
# æ—¢å­˜ã®deep.pyã«ã¯ã‚ã‚‹ãŒã€LightGBMã«ã¯æœªå®Ÿè£…
# å®Ÿè£…æ™‚é–“: 1æ™‚é–“

def calculate_angular_features(rot_data):
    # Angular velocity
    angular_vel = calculate_angular_velocity(rot_data)
    
    # Angular distance (é€£ç¶šãƒ•ãƒ¬ãƒ¼ãƒ é–“ã®å›è»¢è§’)
    angular_dist = calculate_angular_distance(rot_data)
    
    return {
        'angular_vel_mag': np.linalg.norm(angular_vel, axis=1),
        'angular_dist': angular_dist,
        'angular_vel_x': angular_vel[:, 0],
        'angular_vel_y': angular_vel[:, 1],
        'angular_vel_z': angular_vel[:, 2]
    }
```

### Priority 2: StratifiedGroupKFoldæ¤œè¨¼ï¼ˆå½±éŸ¿åº¦: â˜…â˜…â˜…â˜…â˜†ï¼‰

```python
# ç¾åœ¨: train_test_split â†’ éå­¦ç¿’ã®ãƒªã‚¹ã‚¯
# æ”¹å–„: StratifiedGroupKFold â†’ é©åˆ‡ãªæ±åŒ–æ€§èƒ½è©•ä¾¡
# å®Ÿè£…æ™‚é–“: 1æ™‚é–“

from sklearn.model_selection import StratifiedGroupKFold

sgkf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)

for fold, (train_idx, val_idx) in enumerate(sgkf.split(X, y, groups=subjects)):
    X_train, X_val = X[train_idx], X[val_idx]
    y_train, y_val = y[train_idx], y[val_idx]
    
    # ãƒ¢ãƒ‡ãƒ«è¨“ç·´
    model = train_model(X_train, y_train)
    
    # æ¤œè¨¼
    val_pred = model.predict(X_val)
    score = calculate_competition_metric(y_val, val_pred)
```

### Priority 3: ç°¡æ˜“ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼ˆå½±éŸ¿åº¦: â˜…â˜…â˜…â˜…â˜†ï¼‰

```python
# 5ãƒ¢ãƒ‡ãƒ«ã®å˜ç´”å¹³å‡ã§ã‚‚åŠ¹æœå¤§
# å®Ÿè£…æ™‚é–“: 2æ™‚é–“

models = []

# Model 1: LightGBM (IMU only)
models.append(train_lightgbm_imu_only())

# Model 2: LightGBM (Full features)
models.append(train_lightgbm_full())

# Model 3: XGBoost
models.append(train_xgboost())

# Model 4: Deep Learning (æ—¢å­˜ã®deep.py)
models.append(load_deep_model())

# Model 5: CatBoost
models.append(train_catboost())

# æ¨è«–
def ensemble_predict(X):
    predictions = []
    for model in models:
        pred = model.predict_proba(X)
        predictions.append(pred)
    
    # å˜ç´”å¹³å‡
    ensemble_pred = np.mean(predictions, axis=0)
    return ensemble_pred.argmax(axis=1)
```

### Priority 4: FFTç‰¹å¾´é‡ï¼ˆå½±éŸ¿åº¦: â˜…â˜…â˜…â˜†â˜†ï¼‰

```python
# å‘¨æœŸçš„ãªå‹•ä½œãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ•æ‰
# å®Ÿè£…æ™‚é–“: 1æ™‚é–“

def extract_fft_features(signal, sample_rate=20):
    fft_vals = np.abs(fft(signal))
    freqs = fftfreq(len(signal), 1/sample_rate)
    
    # æ­£ã®å‘¨æ³¢æ•°ã®ã¿
    pos_mask = freqs > 0
    fft_vals = fft_vals[pos_mask]
    freqs = freqs[pos_mask]
    
    return {
        'dominant_freq': freqs[np.argmax(fft_vals)],
        'spectral_energy': np.sum(fft_vals**2),
        'spectral_entropy': -np.sum((fft_vals/np.sum(fft_vals)) * 
                                    np.log2(fft_vals/np.sum(fft_vals) + 1e-10))
    }
```

## ğŸ“‹ å®Ÿè£…ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆï¼ˆ1æ—¥ã§å®Œäº†å¯èƒ½ï¼‰

### Morning (3-4 hours)
- [ ] éšå±¤çš„åˆ†é¡å™¨ã®å®Ÿè£…ã¨ãƒ†ã‚¹ãƒˆ
- [ ] Angular velocity/distanceç‰¹å¾´é‡ã®è¿½åŠ 
- [ ] StratifiedGroupKFoldã®å®Ÿè£…

### Afternoon (3-4 hours)
- [ ] 5ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã®æ§‹ç¯‰
- [ ] FFTç‰¹å¾´é‡ã®è¿½åŠ 
- [ ] çµ±åˆãƒ†ã‚¹ãƒˆã¨æ¤œè¨¼

### Evening (1-2 hours)
- [ ] Kaggleæå‡ºç”¨ã‚³ãƒ¼ãƒ‰ã®æº–å‚™
- [ ] ãƒ­ãƒ¼ã‚«ãƒ«æ¤œè¨¼çµæœã®ç¢ºèª
- [ ] æå‡ºã¨LBã‚¹ã‚³ã‚¢ç¢ºèª

## ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆã‚³ãƒ¼ãƒ‰

```python
# main.py - çµ±åˆå®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ

import numpy as np
import pandas as pd
from pathlib import Path

# 1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
train_df = pd.read_csv('train.csv')
demo_df = pd.read_csv('train_demographics.csv')

# 2. ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
features = extract_all_features(train_df)

# 3. éšå±¤çš„åˆ†é¡å™¨ã®è¨“ç·´
hierarchical_clf = HierarchicalClassifier()
hierarchical_clf.fit(features, labels, groups=subjects, cv='sgkf')

# 4. ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«
ensemble = EnsembleClassifier([
    hierarchical_clf,
    lightgbm_model,
    xgboost_model,
    deep_model,
    catboost_model
])

# 5. æ¤œè¨¼
val_score = ensemble.validate()
print(f"Validation Score: {val_score}")

# 6. æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ
if val_score > 0.8:
    generate_submission(ensemble)
```

## âš¡ å³åŠ¹æ€§ã®ã‚ã‚‹æ”¹å–„ï¼ˆ30åˆ†ä»¥å†…ã§å®Ÿè£…å¯èƒ½ï¼‰

### 1. Class Weightèª¿æ•´
```python
# ç¾åœ¨: balanced
# æ”¹å–„: BFRBã‚¯ãƒ©ã‚¹ã«ã‚ˆã‚Šé«˜ã„é‡ã¿

class_weights = compute_class_weight('balanced', 
                                    classes=np.unique(y), 
                                    y=y)
# BFRBã‚¯ãƒ©ã‚¹ï¼ˆ0-7ï¼‰ã®é‡ã¿ã‚’1.5å€ã«
class_weights[:8] *= 1.5
```

### 2. å¾Œå‡¦ç†ã®è¿½åŠ 
```python
def post_process_predictions(predictions):
    # Binaryåˆ†é¡ã®ä¿¡é ¼åº¦ãŒä½ã„å ´åˆã¯èª¿æ•´
    binary_conf = np.max([predictions[:8].sum(), predictions[8:].sum()])
    
    if binary_conf < 0.7:
        # ä¿¡é ¼åº¦ãŒä½ã„å ´åˆã¯ã€ã‚ˆã‚Šä¿å®ˆçš„ãªäºˆæ¸¬ã«
        predictions = smooth_predictions(predictions)
    
    return predictions
```

### 3. TOFæ¬ ææ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
```python
def handle_missing_tof(df):
    # TOFãŒæ¬ æã—ã¦ã„ã‚‹å ´åˆã€IMUç‰¹å¾´é‡ã‚’å¼·åŒ–
    if df['tof_1_v0'].isna().all():
        # IMUç‰¹å¾´é‡ã®é‡ã¿ã‚’å¢—ã‚„ã™
        imu_features = extract_enhanced_imu_features(df)
        return imu_features
    else:
        return extract_all_features(df)
```

## ğŸ“Š æœŸå¾…ã•ã‚Œã‚‹æ”¹å–„åŠ¹æœ

| å®Ÿè£…é …ç›® | å®Ÿè£…æ™‚é–“ | Binary F1æ”¹å–„ | Macro F1æ”¹å–„ | ç·åˆã‚¹ã‚³ã‚¢æ”¹å–„ |
|---------|---------|-------------|-------------|--------------|
| éšå±¤çš„åˆ†é¡ | 3æ™‚é–“ | +0.5% | +20% | +10% |
| Angularç‰¹å¾´é‡ | 1æ™‚é–“ | +0.2% | +5% | +2.5% |
| SGKFæ¤œè¨¼ | 1æ™‚é–“ | 0% | +10% | +5% |
| ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ« | 2æ™‚é–“ | +0.3% | +15% | +7.5% |
| FFTç‰¹å¾´é‡ | 1æ™‚é–“ | +0.1% | +3% | +1.5% |
| **åˆè¨ˆ** | **8æ™‚é–“** | **+1.1%** | **+53%** | **+26.5%** |

### äºˆæ¸¬æœ€çµ‚ã‚¹ã‚³ã‚¢
- Binary F1: 0.957 (0.9459 â†’ 0.957)
- Macro F1: 0.726 (0.473 â†’ 0.726)
- **Combined: 0.841** (0.7094 â†’ 0.841)

## ğŸ”¥ å®Ÿè£…ã®ã‚³ãƒ„

1. **ä¸¦åˆ—é–‹ç™º**: éšå±¤çš„åˆ†é¡ã¨ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã¯ç‹¬ç«‹ã—ã¦é–‹ç™ºå¯èƒ½
2. **æ—¢å­˜ã‚³ãƒ¼ãƒ‰ã®æ´»ç”¨**: deep.pyã®ç‰¹å¾´é‡é–¢æ•°ã‚’æµç”¨
3. **æ®µéšçš„ãƒ†ã‚¹ãƒˆ**: å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’å€‹åˆ¥ã«æ¤œè¨¼ã—ã¦ã‹ã‚‰çµ±åˆ
4. **æ—©æœŸæå‡º**: å®Œç’§ã‚’æ±‚ã‚ãšã€ã¾ãšæå‡ºã—ã¦LBãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å¾—ã‚‹

## ğŸ“ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚ˆãã‚ã‚‹å•é¡Œã¨è§£æ±ºç­–

1. **ãƒ¡ãƒ¢ãƒªä¸è¶³**
   - è§£æ±º: ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²å‡¦ç†ã€ä¸è¦ãªç‰¹å¾´é‡ã‚’å‰Šé™¤

2. **è¨“ç·´æ™‚é–“ãŒé•·ã„**
   - è§£æ±º: n_estimatorsã‚’æ¸›ã‚‰ã™ã€early_stoppingã‚’ä½¿ç”¨

3. **éå­¦ç¿’**
   - è§£æ±º: regularizationãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å¢—ã‚„ã™ã€dropoutã‚’è¿½åŠ 

4. **ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡**
   - è§£æ±º: focal_lossã‚’ä½¿ç”¨ã€SMOTEã§ã‚ªãƒ¼ãƒãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°

---

**é‡è¦**: ã¾ãšéšå±¤çš„åˆ†é¡ã‚’å®Ÿè£…ã—ã€å‹•ä½œç¢ºèªå¾Œã«ä»–ã®æ”¹å–„ã‚’è¿½åŠ ã—ã¦ã„ãã€‚
å®Œç’§ã‚’æ±‚ã‚ãšã€iterativeã«æ”¹å–„ã—ã¦ã„ãã“ã¨ãŒé‡è¦ã€‚