{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7dcccd9",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-06T13:36:39.075557Z",
     "iopub.status.busy": "2025-06-06T13:36:39.075212Z",
     "iopub.status.idle": "2025-06-06T13:36:41.129452Z",
     "shell.execute_reply": "2025-06-06T13:36:41.128208Z"
    },
    "papermill": {
     "duration": 2.059803,
     "end_time": "2025-06-06T13:36:41.131193",
     "exception": false,
     "start_time": "2025-06-06T13:36:39.071390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/cmi-optimized-model/optimized_full_model.pkl\n",
      "/kaggle/input/cmi-detect-behavior-with-sensor-data/train_demographics.csv\n",
      "/kaggle/input/cmi-detect-behavior-with-sensor-data/test_demographics.csv\n",
      "/kaggle/input/cmi-detect-behavior-with-sensor-data/train.csv\n",
      "/kaggle/input/cmi-detect-behavior-with-sensor-data/test.csv\n",
      "/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/cmi_inference_server.py\n",
      "/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/cmi_gateway.py\n",
      "/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/__init__.py\n",
      "/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/core/templates.py\n",
      "/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/core/base_gateway.py\n",
      "/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/core/relay.py\n",
      "/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/core/kaggle_evaluation.proto\n",
      "/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/core/__init__.py\n",
      "/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/core/generated/kaggle_evaluation_pb2.py\n",
      "/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/core/generated/kaggle_evaluation_pb2_grpc.py\n",
      "/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/core/generated/__init__.py\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d70ce09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T13:36:41.137315Z",
     "iopub.status.busy": "2025-06-06T13:36:41.136880Z",
     "iopub.status.idle": "2025-06-06T13:36:52.067550Z",
     "shell.execute_reply": "2025-06-06T13:36:52.066301Z"
    },
    "papermill": {
     "duration": 10.935737,
     "end_time": "2025-06-06T13:36:52.069192",
     "exception": false,
     "start_time": "2025-06-06T13:36:41.133455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "モデルを読み込み中...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LabelEncoder from version 1.6.1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [13:36:50] WARNING: /workspace/src/common/error_msg.h:80: If you are loading a serialized model (like pickle in Python, RDS in R) or\n",
      "configuration generated by an older version of XGBoost, please export the model by calling\n",
      "`Booster.save_model` from that version first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/stable/tutorials/saving_model.html\n",
      "\n",
      "for more details about differences between saving model and serializing.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "テストデータを読み込み中...\n",
      "テストデータ: 107行\n",
      "予測を実行中...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 12.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "提出ファイルを作成中...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 完了！submission.parquetを作成しました\n",
      "予測数: 107\n",
      "              row_id                   gesture\n",
      "0  SEQ_000001_000000  Forehead - pull hairline\n",
      "1  SEQ_000001_000001  Forehead - pull hairline\n",
      "2  SEQ_000001_000002  Forehead - pull hairline\n",
      "3  SEQ_000001_000003  Forehead - pull hairline\n",
      "4  SEQ_000001_000004  Forehead - pull hairline\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "\n",
    "# モデルロード\n",
    "print(\"モデルを読み込み中...\")\n",
    "model_data = joblib.load('/kaggle/input/cmi-optimized-model/optimized_full_model.pkl')\n",
    "models = model_data['models']\n",
    "le = model_data['label_encoder']\n",
    "feature_names = model_data['feature_names']\n",
    "\n",
    "# テストデータ読み込み\n",
    "print(\"テストデータを読み込み中...\")\n",
    "test_df = pd.read_csv('/kaggle/input/cmi-detect-behavior-with-sensor-data/test.csv')\n",
    "print(f\"テストデータ: {len(test_df):,}行\")\n",
    "\n",
    "# BFRBジェスチャー定義\n",
    "BFRB_GESTURES = [\n",
    "  'Above ear - pull hair', 'Cheek - pinch skin', 'Eyebrow - pull hair',\n",
    "  'Eyelash - pull hair', 'Forehead - pull hairline', 'Neck - pinch skin',\n",
    "  'Pinch knee/leg skin', 'Neck - scratch', 'Forehead - scratch',\n",
    "  'Scratch knee/leg skin'\n",
    "]\n",
    "\n",
    "def create_optimized_features(seq_data):\n",
    "  \"\"\"特徴量作成\"\"\"\n",
    "  features = {}\n",
    "\n",
    "  # 加速度特徴量\n",
    "  for axis in ['x', 'y', 'z']:\n",
    "      col = f'acc_{axis}'\n",
    "      data = seq_data[col].values\n",
    "\n",
    "      features[f'{col}_mean'] = np.mean(data)\n",
    "      features[f'{col}_std'] = np.std(data)\n",
    "      features[f'{col}_max'] = np.max(data)\n",
    "      features[f'{col}_min'] = np.min(data)\n",
    "      features[f'{col}_range'] = features[f'{col}_max'] - features[f'{col}_min']\n",
    "      features[f'{col}_p25'] = np.percentile(data, 25)\n",
    "      features[f'{col}_p75'] = np.percentile(data, 75)\n",
    "      features[f'{col}_iqr'] = features[f'{col}_p75'] - features[f'{col}_p25']\n",
    "\n",
    "      diff1 = np.diff(data)\n",
    "      if len(diff1) > 0:\n",
    "          features[f'{col}_diff_mean'] = np.mean(diff1)\n",
    "          features[f'{col}_diff_std'] = np.std(diff1)\n",
    "\n",
    "  # 加速度の大きさ\n",
    "  acc_mag = np.sqrt(seq_data['acc_x']**2 + seq_data['acc_y']**2 + seq_data['acc_z']**2)\n",
    "  features['acc_mag_mean'] = np.mean(acc_mag)\n",
    "  features['acc_mag_std'] = np.std(acc_mag)\n",
    "  features['acc_mag_max'] = np.max(acc_mag)\n",
    "  features['acc_mag_min'] = np.min(acc_mag)\n",
    "\n",
    "  # 角度特徴\n",
    "  features['acc_xy_angle_mean'] = np.mean(np.arctan2(seq_data['acc_y'], seq_data['acc_x']))\n",
    "  features['acc_xy_angle_std'] = np.std(np.arctan2(seq_data['acc_y'], seq_data['acc_x']))\n",
    "\n",
    "  # エネルギー\n",
    "  features['acc_energy'] = np.sum(acc_mag**2) / len(acc_mag)\n",
    "  features['acc_log_energy'] = np.log1p(features['acc_energy'])\n",
    "\n",
    "  # ジャイロ特徴\n",
    "  for axis in ['w', 'x', 'y', 'z']:\n",
    "      col = f'rot_{axis}'\n",
    "      features[f'{col}_mean'] = seq_data[col].mean()\n",
    "      features[f'{col}_std'] = seq_data[col].std()\n",
    "      features[f'{col}_max'] = seq_data[col].max()\n",
    "      features[f'{col}_min'] = seq_data[col].min()\n",
    "\n",
    "  # 回転の大きさ\n",
    "  rot_mag = np.sqrt(seq_data['rot_x']**2 + seq_data['rot_y']**2 + seq_data['rot_z']**2)\n",
    "  features['rot_mag_mean'] = np.mean(rot_mag)\n",
    "  features['rot_mag_std'] = np.std(rot_mag)\n",
    "  features['rot_energy'] = np.sum(rot_mag**2) / len(rot_mag)\n",
    "\n",
    "  # サーモパイル\n",
    "  for i in range(1, 6):\n",
    "      col = f'thm_{i}'\n",
    "      if col in seq_data.columns:\n",
    "          valid_data = seq_data[seq_data[col] != -1][col]\n",
    "          if len(valid_data) > 0:\n",
    "              features[f'{col}_mean'] = valid_data.mean()\n",
    "              features[f'{col}_std'] = valid_data.std()\n",
    "          else:\n",
    "              features[f'{col}_mean'] = 0\n",
    "              features[f'{col}_std'] = 0\n",
    "\n",
    "  # ToF\n",
    "  if 'tof_1_v0' in seq_data.columns:\n",
    "      for sensor_id in range(1, 6):\n",
    "          tof_cols = [f'tof_{sensor_id}_v{i}' for i in range(64)]\n",
    "          tof_data = seq_data[tof_cols]\n",
    "          valid_mask = (tof_data != -1).any(axis=1)\n",
    "\n",
    "          if valid_mask.any():\n",
    "              valid_tof = tof_data[valid_mask].replace(-1, np.nan)\n",
    "              features[f'tof_{sensor_id}_mean'] = np.nanmean(valid_tof.values)\n",
    "              features[f'tof_{sensor_id}_std'] = np.nanstd(valid_tof.values)\n",
    "              features[f'tof_{sensor_id}_has_data'] = 1\n",
    "          else:\n",
    "              features[f'tof_{sensor_id}_mean'] = 0\n",
    "              features[f'tof_{sensor_id}_std'] = 0\n",
    "              features[f'tof_{sensor_id}_has_data'] = 0\n",
    "\n",
    "  features['sequence_length'] = len(seq_data)\n",
    "\n",
    "  mid = len(seq_data) // 2\n",
    "  if mid > 0:\n",
    "      features['acc_mag_trend'] = np.mean(acc_mag[mid:]) - np.mean(acc_mag[:mid])\n",
    "\n",
    "  return features\n",
    "\n",
    "# 予測処理\n",
    "print(\"予測を実行中...\")\n",
    "predictions = {}\n",
    "\n",
    "for seq_id in tqdm(test_df['sequence_id'].unique()):\n",
    "  seq_data = test_df[test_df['sequence_id'] == seq_id]\n",
    "\n",
    "  if 'phase' in seq_data.columns:\n",
    "      gesture_data = seq_data[seq_data['phase'] == 'Gesture']\n",
    "  else:\n",
    "      gesture_data = seq_data\n",
    "\n",
    "  if len(gesture_data) > 0:\n",
    "      try:\n",
    "          features = create_optimized_features(gesture_data)\n",
    "          X_test = pd.DataFrame([features])[feature_names]\n",
    "\n",
    "          all_probs = []\n",
    "          for model_info in models:\n",
    "              lgb_model = model_info['lgb']\n",
    "              xgb_model = model_info['xgb']\n",
    "\n",
    "              lgb_proba = lgb_model.predict_proba(X_test)[0]\n",
    "              xgb_proba = xgb_model.predict_proba(X_test)[0]\n",
    "\n",
    "              ensemble_proba = 0.7 * lgb_proba + 0.3 * xgb_proba\n",
    "              all_probs.append(ensemble_proba)\n",
    "\n",
    "          final_proba = np.mean(all_probs, axis=0)\n",
    "          pred_class = np.argmax(final_proba)\n",
    "          gesture = le.inverse_transform([pred_class])[0]\n",
    "\n",
    "          for row_id in seq_data['row_id']:\n",
    "              predictions[row_id] = gesture\n",
    "\n",
    "      except Exception as e:\n",
    "          print(f\"エラー: {seq_id} - {e}\")\n",
    "          for row_id in seq_data['row_id']:\n",
    "              predictions[row_id] = 'Text on phone'\n",
    "\n",
    "# 提出ファイル作成\n",
    "print(\"提出ファイルを作成中...\")\n",
    "submission = pd.DataFrame([\n",
    "  {'row_id': row_id, 'gesture': gesture}\n",
    "  for row_id, gesture in predictions.items()\n",
    "])\n",
    "\n",
    "# 欠損チェック\n",
    "all_test_rows = test_df['row_id'].unique()\n",
    "missing_rows = set(all_test_rows) - set(submission['row_id'])\n",
    "\n",
    "if missing_rows:\n",
    "  print(f\"{len(missing_rows)}個の欠損行を補完中...\")\n",
    "  missing_df = pd.DataFrame({\n",
    "      'row_id': list(missing_rows),\n",
    "      'gesture': 'Text on phone'\n",
    "  })\n",
    "  submission = pd.concat([submission, missing_df], ignore_index=True)\n",
    "\n",
    "submission = submission.sort_values('row_id').reset_index(drop=True)\n",
    "\n",
    "# 重要: Parquet形式で保存！\n",
    "submission.to_parquet('submission.parquet', index=False)\n",
    "print(f\"\\n✅ 完了！submission.parquetを作成しました\")\n",
    "print(f\"予測数: {len(submission)}\")\n",
    "print(submission.head())\n",
    "\n",
    "# 確認用にCSVも保存\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "# CSVの代わりにParquet形式で保存\n",
    "submission.to_parquet('submission.parquet', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 12518947,
     "isSourceIdPinned": false,
     "sourceId": 102335,
     "sourceType": "competition"
    },
    {
     "datasetId": 7604462,
     "sourceId": 12080011,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19.029423,
   "end_time": "2025-06-06T13:36:53.094103",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-06T13:36:34.064680",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
