{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e28e92c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T12:21:35.910679Z",
     "iopub.status.busy": "2025-06-01T12:21:35.910395Z",
     "iopub.status.idle": "2025-06-01T12:25:49.578158Z",
     "shell.execute_reply": "2025-06-01T12:25:49.577274Z"
    },
    "papermill": {
     "duration": 253.672239,
     "end_time": "2025-06-01T12:25:49.579359",
     "exception": false,
     "start_time": "2025-06-01T12:21:35.907120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-01 12:21:40.162695: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748780500.342929      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748780500.395785      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports loaded\n",
      "Loading dataset...\n",
      "Loaded 574945 rows.\n",
      "Gesture label mapping:\n",
      "  0: Above ear - pull hair\n",
      "  1: Cheek - pinch skin\n",
      "  2: Drink from bottle/cup\n",
      "  3: Eyebrow - pull hair\n",
      "  4: Eyelash - pull hair\n",
      "  5: Feel around in tray and pull out an object\n",
      "  6: Forehead - pull hairline\n",
      "  7: Forehead - scratch\n",
      "  8: Glasses on/off\n",
      "  9: Neck - pinch skin\n",
      "  10: Neck - scratch\n",
      "  11: Pinch knee/leg skin\n",
      "  12: Pull air toward your face\n",
      "  13: Scratch knee/leg skin\n",
      "  14: Text on phone\n",
      "  15: Wave hello\n",
      "  16: Write name in air\n",
      "  17: Write name on leg\n",
      "Checking for IMU-only sequences...\n",
      "Total sequences: 8151\n",
      "IMU-only sequences (all thm_/tof_ null): 96 (1.2%)\n",
      "Ignoring 325 thermopile / time-of-flight columns.\n",
      "Using 7 numeric feature columns for training:\n",
      "['acc_x', 'acc_y', 'acc_z', 'rot_w', 'rot_x', 'rot_y', 'rot_z']\n",
      "\n",
      "Total missing values in feature columns: 14768\n",
      "Columns with missing values:\n",
      "rot_w    3692\n",
      "rot_x    3692\n",
      "rot_y    3692\n",
      "rot_z    3692\n",
      "dtype: int64\n",
      "Building sequences...\n",
      "Processing sequence 0...\n",
      "Processing sequence 500...\n",
      "Processing sequence 1000...\n",
      "Processing sequence 1500...\n",
      "Processing sequence 2000...\n",
      "Processing sequence 2500...\n",
      "Processing sequence 3000...\n",
      "Processing sequence 3500...\n",
      "Processing sequence 4000...\n",
      "Processing sequence 4500...\n",
      "Processing sequence 5000...\n",
      "Processing sequence 5500...\n",
      "Processing sequence 6000...\n",
      "Processing sequence 6500...\n",
      "Processing sequence 7000...\n",
      "Processing sequence 7500...\n",
      "Processing sequence 8000...\n",
      "Sequence length stats - Min: 29, Avg: 70, 90th percentile: 103\n",
      "Padding / truncating all sequences to fixed length 103...\n",
      "Integer labels: [ 1  6  1 17]\n",
      "After one-hot encoding: [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Building CNN-GRU model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "I0000 00:00:1748780564.320785      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,408</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">41,088</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">82,048</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">229,632</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">459,008</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">296,448</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">123,648</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,322</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m1,408\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │          \u001b[38;5;34m12,352\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m49\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m49\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │          \u001b[38;5;34m41,088\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │          \u001b[38;5;34m82,048\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │         \u001b[38;5;34m229,632\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │           \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │         \u001b[38;5;34m459,008\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │         \u001b[38;5;34m296,448\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m123,648\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │          \u001b[38;5;34m66,048\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │           \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m131,328\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │           \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m32,896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)                  │           \u001b[38;5;34m2,322\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,483,090</span> (5.66 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,483,090\u001b[0m (5.66 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,480,658</span> (5.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,480,658\u001b[0m (5.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,432</span> (9.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,432\u001b[0m (9.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CNN-GRU model...\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1748780588.311936      58 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 116ms/step - accuracy: 0.0659 - loss: 3.6902 - val_accuracy: 0.0681 - val_loss: 2.8114 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.1079 - loss: 3.0649 - val_accuracy: 0.0797 - val_loss: 2.8555 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.1282 - loss: 2.8594 - val_accuracy: 0.0889 - val_loss: 2.8364 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.1714 - loss: 2.5980 - val_accuracy: 0.1042 - val_loss: 2.8906 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.1715 - loss: 2.5089 - val_accuracy: 0.1294 - val_loss: 2.9089 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.1980 - loss: 2.3842 - val_accuracy: 0.1392 - val_loss: 2.6890 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.2127 - loss: 2.3022 - val_accuracy: 0.1435 - val_loss: 2.6275 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.2215 - loss: 2.2232 - val_accuracy: 0.1950 - val_loss: 2.4516 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.2538 - loss: 2.1309 - val_accuracy: 0.2048 - val_loss: 2.3300 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.2549 - loss: 2.1277 - val_accuracy: 0.2826 - val_loss: 2.0540 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.2810 - loss: 2.0383 - val_accuracy: 0.2704 - val_loss: 2.0571 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.2918 - loss: 2.0112 - val_accuracy: 0.2998 - val_loss: 1.9882 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.2919 - loss: 1.9478 - val_accuracy: 0.2955 - val_loss: 2.0193 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.3063 - loss: 1.9260 - val_accuracy: 0.3047 - val_loss: 1.9970 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.3167 - loss: 1.9058 - val_accuracy: 0.3243 - val_loss: 1.9292 - learning_rate: 0.0010\n",
      "Epoch 16/60\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.3262 - loss: 1.8393 - val_accuracy: 0.3133 - val_loss: 1.9223 - learning_rate: 0.0010\n",
      "Epoch 17/60\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.3326 - loss: 1.8386 - val_accuracy: 0.3188 - val_loss: 1.9391 - learning_rate: 0.0010\n",
      "Epoch 18/60\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.3480 - loss: 1.7989 - val_accuracy: 0.3403 - val_loss: 1.9607 - learning_rate: 0.0010\n",
      "Epoch 19/60\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.3498 - loss: 1.7813 - val_accuracy: 0.3268 - val_loss: 1.9757 - learning_rate: 0.0010\n",
      "Epoch 20/60\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.3598 - loss: 1.7467 - val_accuracy: 0.3335 - val_loss: 1.9730 - learning_rate: 0.0010\n",
      "Epoch 21/60\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.3729 - loss: 1.7415\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.3728 - loss: 1.7415 - val_accuracy: 0.3384 - val_loss: 1.9690 - learning_rate: 0.0010\n",
      "Epoch 22/60\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.3805 - loss: 1.6907 - val_accuracy: 0.3538 - val_loss: 1.8435 - learning_rate: 5.0000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.3939 - loss: 1.6310 - val_accuracy: 0.3666 - val_loss: 1.8469 - learning_rate: 5.0000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.4047 - loss: 1.6091 - val_accuracy: 0.3703 - val_loss: 1.8381 - learning_rate: 5.0000e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.4005 - loss: 1.6266 - val_accuracy: 0.3660 - val_loss: 1.8298 - learning_rate: 5.0000e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.4152 - loss: 1.5973 - val_accuracy: 0.3820 - val_loss: 1.8394 - learning_rate: 5.0000e-04\n",
      "Epoch 27/60\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.4174 - loss: 1.5946 - val_accuracy: 0.3881 - val_loss: 1.7941 - learning_rate: 5.0000e-04\n",
      "Epoch 28/60\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.4287 - loss: 1.5491 - val_accuracy: 0.3832 - val_loss: 1.7777 - learning_rate: 5.0000e-04\n",
      "Epoch 29/60\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.4178 - loss: 1.5557 - val_accuracy: 0.3948 - val_loss: 1.7928 - learning_rate: 5.0000e-04\n",
      "Epoch 30/60\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.4415 - loss: 1.5244 - val_accuracy: 0.3691 - val_loss: 1.8747 - learning_rate: 5.0000e-04\n",
      "Epoch 31/60\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.4314 - loss: 1.5238 - val_accuracy: 0.3814 - val_loss: 1.8646 - learning_rate: 5.0000e-04\n",
      "Epoch 32/60\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.4372 - loss: 1.5177 - val_accuracy: 0.3863 - val_loss: 1.8026 - learning_rate: 5.0000e-04\n",
      "Epoch 33/60\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.4539 - loss: 1.5009\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.4537 - loss: 1.5011 - val_accuracy: 0.4102 - val_loss: 1.8000 - learning_rate: 5.0000e-04\n",
      "Epoch 34/60\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.4558 - loss: 1.4573 - val_accuracy: 0.3912 - val_loss: 1.8210 - learning_rate: 2.5000e-04\n",
      "Epoch 35/60\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.4730 - loss: 1.4331 - val_accuracy: 0.4053 - val_loss: 1.8123 - learning_rate: 2.5000e-04\n",
      "Epoch 36/60\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.4660 - loss: 1.4311 - val_accuracy: 0.4194 - val_loss: 1.8026 - learning_rate: 2.5000e-04\n",
      "Epoch 37/60\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.4762 - loss: 1.4212 - val_accuracy: 0.4329 - val_loss: 1.7568 - learning_rate: 2.5000e-04\n",
      "Epoch 38/60\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.4815 - loss: 1.4048 - val_accuracy: 0.4108 - val_loss: 1.8161 - learning_rate: 2.5000e-04\n",
      "Epoch 39/60\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.4754 - loss: 1.4002 - val_accuracy: 0.4329 - val_loss: 1.7778 - learning_rate: 2.5000e-04\n",
      "Epoch 40/60\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.4940 - loss: 1.3866 - val_accuracy: 0.4102 - val_loss: 1.8155 - learning_rate: 2.5000e-04\n",
      "Epoch 41/60\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.4890 - loss: 1.3598 - val_accuracy: 0.4261 - val_loss: 1.7996 - learning_rate: 2.5000e-04\n",
      "Epoch 42/60\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.4904 - loss: 1.3775\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.4904 - loss: 1.3776 - val_accuracy: 0.4255 - val_loss: 1.7802 - learning_rate: 2.5000e-04\n",
      "Epoch 43/60\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.4919 - loss: 1.3601 - val_accuracy: 0.4329 - val_loss: 1.7635 - learning_rate: 1.2500e-04\n",
      "Epoch 44/60\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.5059 - loss: 1.3225 - val_accuracy: 0.4341 - val_loss: 1.7755 - learning_rate: 1.2500e-04\n",
      "Epoch 45/60\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.5127 - loss: 1.3261 - val_accuracy: 0.4304 - val_loss: 1.8314 - learning_rate: 1.2500e-04\n",
      "Epoch 46/60\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.5058 - loss: 1.3006 - val_accuracy: 0.4378 - val_loss: 1.7794 - learning_rate: 1.2500e-04\n",
      "Epoch 47/60\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5187 - loss: 1.3216\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.5185 - loss: 1.3216 - val_accuracy: 0.4372 - val_loss: 1.7777 - learning_rate: 1.2500e-04\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Training complete.\n",
      "Predicting on validation set...\n",
      "Estimated leaderboard (val) score: 0.6354\n",
      "\n",
      "Running manual test...\n",
      "Manual prediction result for sequence_id SEQ_000001: Eyebrow - pull hair\n"
     ]
    }
   ],
   "source": [
    "#score 0.63 - 0.65, good luck for you. Upload if you like it \n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import GRU, Bidirectional, GlobalAveragePooling1D\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "import tensorflow as tf\n",
    "import polars as pl\n",
    "import kaggle_evaluation.cmi_inference_server\n",
    "print(\"Imports loaded\")\n",
    "\n",
    "# Load the dataset\n",
    "print(\"Loading dataset...\")\n",
    "df = pd.read_csv('/kaggle/input/cmi-detect-behavior-with-sensor-data/train.csv')\n",
    "print(f\"Loaded {len(df)} rows.\")\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['gesture'] = label_encoder.fit_transform(df['gesture'].astype(str))\n",
    "\n",
    "# Save class names for inference\n",
    "np.save('gesture_classes.npy', label_encoder.classes_)\n",
    "\n",
    "# Print class label mapping\n",
    "print(\"Gesture label mapping:\")\n",
    "for idx, label in enumerate(label_encoder.classes_):\n",
    "    print(f\"  {idx}: {label}\")\n",
    "\n",
    "print(\"Checking for IMU-only sequences...\")\n",
    "\n",
    "def check_for_imu_only_seqs():\n",
    "    # Identify thermopile and TOF columns\n",
    "    thermal_tof_cols = [col for col in df.columns if col.startswith('thm_') or col.startswith('tof_')]\n",
    "    \n",
    "    # Group by sequence and check if all thm_/tof_ values are null\n",
    "    imu_only_flags = df[thermal_tof_cols].isna().groupby(df['sequence_id']).all().all(axis=1)\n",
    "    \n",
    "    # Report statistics\n",
    "    total_sequences = df['sequence_id'].nunique()\n",
    "    imu_only_count = imu_only_flags.sum()\n",
    "    imu_only_pct = (imu_only_count / total_sequences) * 100\n",
    "    \n",
    "    print(f\"Total sequences: {total_sequences}\")\n",
    "    print(f\"IMU-only sequences (all thm_/tof_ null): {imu_only_count} ({imu_only_pct:.1f}%)\")\n",
    "\n",
    "check_for_imu_only_seqs()\n",
    "\n",
    "excluded_cols = {\n",
    "    'gesture', 'sequence_type', 'behavior', 'orientation',  # train-only\n",
    "    'row_id', 'subject', 'phase',  # metadata\n",
    "    'sequence_id', 'sequence_counter'  # identifiers\n",
    "}\n",
    "\n",
    "# Setting this true makes model ignore thermal and tof data\n",
    "drop_thermal_and_tof = True\n",
    "\n",
    "if drop_thermal_and_tof:\n",
    "    thermal_tof_cols = [col for col in df.columns if col.startswith('thm_') or col.startswith('tof_')]\n",
    "    excluded_cols.update(thermal_tof_cols)\n",
    "    print(f\"Ignoring {len(thermal_tof_cols)} thermopile / time-of-flight columns.\")\n",
    "\n",
    "# Select numeric feature columns\n",
    "feature_cols = [col for col in df.columns if col not in excluded_cols]\n",
    "print(f\"Using {len(feature_cols)} numeric feature columns for training:\")\n",
    "print(feature_cols)\n",
    "\n",
    "# Check for NaNs in selected feature columns\n",
    "nan_counts = df[feature_cols].isna().sum()\n",
    "total_nans = nan_counts.sum()\n",
    "print(f\"\\nTotal missing values in feature columns: {total_nans}\")\n",
    "if total_nans > 0:\n",
    "    print(\"Columns with missing values:\")\n",
    "    print(nan_counts[nan_counts > 0])\n",
    "else:\n",
    "    print(\"No missing values found in feature columns.\")\n",
    "\n",
    "def preprocess_sequence(df_sequence: pd.DataFrame, feature_cols: list) -> np.ndarray:\n",
    "    data = df_sequence[feature_cols].copy()\n",
    "    data = data.ffill().bfill().fillna(0)\n",
    "    scaled = StandardScaler().fit_transform(data)\n",
    "    return scaled\n",
    "\n",
    "# Build sequences\n",
    "sequence_ids = df['sequence_id'].unique()\n",
    "sequences = df.groupby('sequence_id')\n",
    "\n",
    "X = []\n",
    "seq_lengths = []\n",
    "\n",
    "print(\"Building sequences...\")\n",
    "for i, (seq_id, seq) in enumerate(sequences):\n",
    "    if i % 500 == 0:\n",
    "        print(f\"Processing sequence {i}...\")\n",
    "    processed = preprocess_sequence(seq, feature_cols)\n",
    "    X.append(processed)\n",
    "    seq_lengths.append(processed.shape[0])\n",
    "\n",
    "max_len_perentile = 90\n",
    "\n",
    "# Report sequence length stats\n",
    "minlen = min(seq_lengths)\n",
    "avglen = int(np.mean(seq_lengths))\n",
    "pad_len_to_use = int(np.percentile(seq_lengths, max_len_perentile))  \n",
    "print(f\"Sequence length stats - Min: {minlen}, Avg: {avglen}, {max_len_perentile}th percentile: {pad_len_to_use}\")\n",
    "print(f\"Padding / truncating all sequences to fixed length {pad_len_to_use}...\")\n",
    "\n",
    "np.save(\"sequence_maxlen.npy\", pad_len_to_use)  # Save for inference\n",
    "\n",
    "# Pad/truncate to fixed length\n",
    "X = pad_sequences(X, maxlen=pad_len_to_use, dtype='float32', padding='post', truncating='post')\n",
    "\n",
    "# Use groupby to get the first gesture per sequence (already integer-encoded)\n",
    "y = df.groupby('sequence_id')['gesture'].first().values\n",
    "\n",
    "print(\"Integer labels:\", y[:4])\n",
    "\n",
    "# Convert to one-hot vectors\n",
    "num_classes = len(np.unique(y))\n",
    "y = to_categorical(y, num_classes=num_classes)\n",
    "\n",
    "print(\"After one-hot encoding:\", y[:4])\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build CNN-GRU model\n",
    "print(\"Building CNN-GRU model...\")\n",
    "model = Sequential([\n",
    "    # Multi-scale CNN blocks for feature extraction\n",
    "    Conv1D(64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    BatchNormalization(),\n",
    "    Conv1D(64, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(2),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    MaxPooling1D(2),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Conv1D(256, kernel_size=7, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Conv1D(256, kernel_size=7, activation='relu'),\n",
    "    MaxPooling1D(2),\n",
    "    Dropout(0.4),\n",
    "    \n",
    "    # Bidirectional GRU for temporal dependencies (more efficient than LSTM)\n",
    "    Bidirectional(GRU(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.3)),\n",
    "    Bidirectional(GRU(64, return_sequences=False, dropout=0.3, recurrent_dropout=0.3)),\n",
    "    \n",
    "    # Dense layers for classification\n",
    "    Dense(512, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile model with categorical crossentropy loss (for one-hot labels)\n",
    "model.compile(\n",
    "    optimizer=AdamW(learning_rate=0.001, weight_decay=1e-4), \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "# Define callbacks for better training\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-7, verbose=1),\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
    "]\n",
    "\n",
    "# Train model using explicitly split validation set (80/20 held out)\n",
    "print(\"Training CNN-GRU model...\")\n",
    "history = model.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=60, \n",
    "    batch_size=128, \n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "model.save(\"gesture_cnn_gru_model.h5\")\n",
    "print(\"Training complete.\")\n",
    "\n",
    "from cmi_2025_metric_copy_for_import import CompetitionMetric\n",
    "\n",
    "# Get predicted labels for the validation set\n",
    "print(\"Predicting on validation set...\")\n",
    "y_val_pred_probs = model.predict(X_val, verbose=0)\n",
    "y_val_pred = np.argmax(y_val_pred_probs, axis=1)\n",
    "y_val_true = np.argmax(y_val, axis=1)\n",
    "\n",
    "# Map integer labels back to gesture strings\n",
    "gesture_classes = np.load(\"gesture_classes.npy\", allow_pickle=True)\n",
    "val_pred_labels = pd.Series(y_val_pred).map(lambda i: gesture_classes[i])\n",
    "val_true_labels = pd.Series(y_val_true).map(lambda i: gesture_classes[i])\n",
    "\n",
    "# Build DataFrames for the metric\n",
    "val_submission = pd.DataFrame({'gesture': val_pred_labels})\n",
    "val_solution = pd.DataFrame({'gesture': val_true_labels})\n",
    "\n",
    "# Run competition metric\n",
    "metric = CompetitionMetric()\n",
    "score = metric.calculate_hierarchical_f1(val_solution, val_submission)\n",
    "print(f\"Estimated leaderboard (val) score: {score:.4f}\")\n",
    "\n",
    "def predict(sequence: pl.DataFrame, demographics: pl.DataFrame) -> str:\n",
    "    df_seq = sequence.to_pandas()\n",
    "    processed = preprocess_sequence(df_seq, feature_cols)\n",
    "    maxlen = int(np.load(\"sequence_maxlen.npy\"))  # ensure consistent shape\n",
    "    padded = pad_sequences([processed], maxlen=maxlen, dtype='float32', padding='post', truncating='post')\n",
    "    model = load_model(\"gesture_cnn_gru_model.h5\")\n",
    "    prediction = model.predict(padded, verbose=0)\n",
    "    predicted_index = np.argmax(prediction, axis=1)[0]\n",
    "    gesture_classes = np.load(\"gesture_classes.npy\", allow_pickle=True)\n",
    "    return gesture_classes[predicted_index]\n",
    "\n",
    "# Launch inference server\n",
    "inference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(\n",
    "        data_paths=(\n",
    "            '/kaggle/input/cmi-detect-behavior-with-sensor-data/test.csv',\n",
    "            '/kaggle/input/cmi-detect-behavior-with-sensor-data/test_demographics.csv',\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Manual test (only runs outside Kaggle gateway)\n",
    "if not os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    print(\"\\nRunning manual test...\")\n",
    "    test_df = pd.read_csv('/kaggle/input/cmi-detect-behavior-with-sensor-data/test.csv')\n",
    "    sample_seq_id = test_df['sequence_id'].unique()[0]\n",
    "    test_seq = test_df[test_df['sequence_id'] == sample_seq_id]\n",
    "    prediction = predict(pl.DataFrame(test_seq), None)\n",
    "    print(f\"Manual prediction result for sequence_id {sample_seq_id}: {prediction}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 12518947,
     "sourceId": 102335,
     "sourceType": "competition"
    },
    {
     "sourceId": 242954653,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 261.404297,
   "end_time": "2025-06-01T12:25:53.135842",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-01T12:21:31.731545",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
