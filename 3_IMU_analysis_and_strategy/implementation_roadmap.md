# ğŸ—ºï¸ IMUãƒ¢ãƒ‡ãƒ«æ”¹å–„å®Ÿè£…ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—

## ğŸ“‹ ç¾çŠ¶ã®èª²é¡Œã‚µãƒãƒªãƒ¼

### ã‚¹ã‚³ã‚¢åˆ†æ
| ãƒ¡ãƒˆãƒªã‚¯ã‚¹ | ç¾åœ¨å€¤ | ç›®æ¨™å€¤ | ã‚®ãƒ£ãƒƒãƒ— |
|----------|--------|--------|---------|
| **å…¨ä½“ã‚¹ã‚³ã‚¢** | 0.709 | 0.770 | +0.061 |
| **Binary F1** | 0.942 | 0.940+ | ç¶­æŒ |
| **Macro F1** | 0.475 | 0.600 | +0.125 |

### æ ¹æœ¬åŸå› 
- âœ… BFRBã®æ¤œå‡ºã¯æˆåŠŸã—ã¦ã„ã‚‹
- âŒ BFRBå†…ã®8ã‚¯ãƒ©ã‚¹åˆ†é¡ãŒå¤±æ•—
- âŒ ã‚¯ãƒ©ã‚¹é–“ã®ç‰¹å¾´ãŒä¸ååˆ†

---

## ğŸ¯ æ”¹å–„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ

### ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ1: äºŒæ®µéšåˆ†é¡ã‚·ã‚¹ãƒ†ãƒ ã€æ¨å¥¨ã€‘

```mermaid
graph LR
    A[å…¥åŠ›ãƒ‡ãƒ¼ã‚¿] --> B[Stage1: Binaryåˆ†é¡]
    B -->|BFRB| C[Stage2A: BFRB 8ã‚¯ãƒ©ã‚¹åˆ†é¡]
    B -->|Non-BFRB| D[Stage2B: Non-BFRB 10ã‚¯ãƒ©ã‚¹åˆ†é¡]
    C --> E[æœ€çµ‚äºˆæ¸¬]
    D --> E
```

**ãƒ¡ãƒªãƒƒãƒˆ:**
- Binary F1ã®é«˜ã•ã‚’æ´»ã‹ã›ã‚‹
- å„æ®µéšã§æœ€é©åŒ–å¯èƒ½
- ã‚¯ãƒ©ã‚¹ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°ãŒå®¹æ˜“

**å®Ÿè£…ã‚³ã‚¹ãƒˆ:** ä½ï¼ˆ2-3æ—¥ï¼‰

### ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ2: éšå±¤çš„åˆ†é¡

```
Level 1: BFRB vs Non-BFRB
Level 2: BFRB subcategories
  â”œâ”€ Hair pulling (4 classes)
  â”‚   â”œâ”€ Above ear - pull hair
  â”‚   â”œâ”€ Eyebrow - pull hair
  â”‚   â”œâ”€ Eyelash - pull hair
  â”‚   â””â”€ Forehead - pull hairline
  â”œâ”€ Skin manipulation (2 classes)
  â”‚   â”œâ”€ Cheek - pinch skin
  â”‚   â””â”€ Neck - pinch skin
  â””â”€ Scratching (2 classes)
      â”œâ”€ Forehead - scratch
      â””â”€ Neck - scratch
```

**ãƒ¡ãƒªãƒƒãƒˆ:**
- é¡ä¼¼è¡Œå‹•ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
- æ®µéšçš„ãªç²¾åº¦å‘ä¸Š
- è§£é‡ˆæ€§ãŒé«˜ã„

**å®Ÿè£…ã‚³ã‚¹ãƒˆ:** ä¸­ï¼ˆ4-5æ—¥ï¼‰

### ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ3: ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯å­¦ç¿’

```python
# è¤‡æ•°ã®ç›®çš„é–¢æ•°ã‚’åŒæ™‚æœ€é©åŒ–
loss = Î± * binary_loss + Î² * multiclass_loss + Î³ * contrastive_loss
```

**ãƒ¡ãƒªãƒƒãƒˆ:**
- End-to-endã®å­¦ç¿’
- ç‰¹å¾´è¡¨ç¾ã®å…±æœ‰
- æœ€æ–°ã®æ·±å±¤å­¦ç¿’æ‰‹æ³•

**å®Ÿè£…ã‚³ã‚¹ãƒˆ:** é«˜ï¼ˆ1é€±é–“ä»¥ä¸Šï¼‰

---

## ğŸ“… å®Ÿè£…ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«

### Week 1: å³åŠ¹æ€§ã®é«˜ã„æ”¹å–„

#### Day 1-2: äºŒæ®µéšåˆ†é¡ã®å®Ÿè£…
- [ ] `TwoStageClassifier`ã‚¯ãƒ©ã‚¹ã®å®Ÿè£…
- [ ] Binary modelã®è¨“ç·´
- [ ] BFRB/Non-BFRBåˆ¥ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
- [ ] æ¤œè¨¼ã¨ã‚¹ã‚³ã‚¢è¨ˆæ¸¬

#### Day 3-4: ã‚¯ãƒ©ã‚¹ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°
- [ ] BFRBã‚¯ãƒ©ã‚¹ã®åˆ†å¸ƒåˆ†æ
- [ ] SMOTEã®å®Ÿè£…
- [ ] ã‚¯ãƒ©ã‚¹ã‚¦ã‚§ã‚¤ãƒˆã®æœ€é©åŒ–
- [ ] äº¤å·®æ¤œè¨¼ã§ã®è©•ä¾¡

#### Day 5-6: ç‰¹å¾´é‡ã®å¾®èª¿æ•´
- [ ] ç‰¹å¾´é‡é‡è¦åº¦ã®åˆ†æ
- [ ] ä¸è¦ãªç‰¹å¾´é‡ã®å‰Šé™¤
- [ ] BFRBç‰¹åŒ–ç‰¹å¾´é‡ã®è¿½åŠ 
- [ ] ç‰¹å¾´é‡é¸æŠã®è‡ªå‹•åŒ–

**æœŸå¾…ã•ã‚Œã‚‹æ”¹å–„:** 0.709 â†’ 0.730

### Week 2: ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®å¼·åŒ–

#### Day 7-8: Linear Acceleration
- [ ] Butterworthãƒ•ã‚£ãƒ«ã‚¿ã®å®Ÿè£…
- [ ] é‡åŠ›æˆåˆ†ã®å‹•çš„æ¨å®š
- [ ] ç·šå½¢åŠ é€Ÿåº¦ã®æŠ½å‡º
- [ ] ç‰¹å¾´é‡ã¸ã®çµ±åˆ

#### Day 9-10: é«˜åº¦ãªå‘¨æ³¢æ•°ç‰¹å¾´
- [ ] ã‚¦ã‚§ãƒ¼ãƒ–ãƒ¬ãƒƒãƒˆå¤‰æ›
- [ ] ãƒ¡ãƒ«å‘¨æ³¢æ•°ã‚±ãƒ—ã‚¹ãƒˆãƒ©ãƒ ä¿‚æ•°(MFCC)
- [ ] ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ã®æ™‚é–“å¤‰åŒ–
- [ ] ã‚¯ãƒ­ã‚¹ã‚¹ãƒšã‚¯ãƒˆãƒ«å¯†åº¦

#### Day 11-12: æ™‚ç³»åˆ—ãƒ‘ã‚¿ãƒ¼ãƒ³
- [ ] DTWãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒãƒƒãƒãƒ³ã‚°
- [ ] Shapeletã®æŠ½å‡º
- [ ] åå¾©ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º
- [ ] å‹•ä½œã®é–‹å§‹/çµ‚äº†æ¤œå‡º

**æœŸå¾…ã•ã‚Œã‚‹æ”¹å–„:** 0.730 â†’ 0.750

### Week 3: æ·±å±¤å­¦ç¿’ã¨ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«

#### Day 13-14: 1D-CNNãƒ¢ãƒ‡ãƒ«
- [ ] ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã®å®Ÿè£…
- [ ] CNNã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆ
- [ ] è¨“ç·´ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
- [ ] ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´

#### Day 15-16: BiLSTMè¿½åŠ 
- [ ] CNN + BiLSTMã®çµ±åˆ
- [ ] Attentionæ©Ÿæ§‹ã®è¿½åŠ 
- [ ] æ®‹å·®æ¥ç¶š
- [ ] ãƒãƒƒãƒæ­£è¦åŒ–

#### Day 17-18: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æœ€é©åŒ–
- [ ] OOFäºˆæ¸¬ã®ç”Ÿæˆ
- [ ] ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ã®å®Ÿè£…
- [ ] é‡ã¿æœ€é©åŒ–
- [ ] æœ€çµ‚èª¿æ•´

**æœŸå¾…ã•ã‚Œã‚‹æ”¹å–„:** 0.750 â†’ 0.770+

---

## ğŸ“ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 

```
3_IMU_two_stage_classification/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ stage1_binary.yaml      # Binaryåˆ†é¡è¨­å®š
â”‚   â”œâ”€â”€ stage2_bfrb.yaml        # BFRB 8ã‚¯ãƒ©ã‚¹è¨­å®š
â”‚   â””â”€â”€ stage2_non_bfrb.yaml    # Non-BFRB 10ã‚¯ãƒ©ã‚¹è¨­å®š
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ two_stage_classifier.py # äºŒæ®µéšåˆ†é¡å™¨
â”‚   â”œâ”€â”€ data_balancing.py       # ã‚¯ãƒ©ã‚¹ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°
â”‚   â”œâ”€â”€ linear_acceleration.py  # ç·šå½¢åŠ é€Ÿåº¦
â”‚   â”œâ”€â”€ advanced_features.py    # é«˜åº¦ãªç‰¹å¾´é‡
â”‚   â”œâ”€â”€ deep_models.py          # æ·±å±¤å­¦ç¿’ãƒ¢ãƒ‡ãƒ«
â”‚   â””â”€â”€ ensemble.py             # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda_class_imbalance.ipynb
â”‚   â”œâ”€â”€ 02_two_stage_training.ipynb
â”‚   â”œâ”€â”€ 03_feature_importance.ipynb
â”‚   â””â”€â”€ 04_ensemble_optimization.ipynb
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ exp001_baseline/        # ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«
â”‚   â”œâ”€â”€ exp002_two_stage/       # äºŒæ®µéšåˆ†é¡
â”‚   â”œâ”€â”€ exp003_balanced/        # ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°
â”‚   â””â”€â”€ exp004_deep_learning/   # æ·±å±¤å­¦ç¿’
â””â”€â”€ results/
    â”œâ”€â”€ cv_scores.csv
    â”œâ”€â”€ confusion_matrices/
    â””â”€â”€ feature_importance/
```

---

## ğŸ”¬ å®Ÿé¨“ç®¡ç†

### å®Ÿé¨“ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°
```python
# experiments/tracking.py

class ExperimentTracker:
    def __init__(self, exp_name):
        self.exp_name = exp_name
        self.metrics = {}
        
    def log_metrics(self, fold, metrics):
        """å„Foldã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨˜éŒ²"""
        self.metrics[fold] = {
            'binary_f1': metrics['binary_f1'],
            'macro_f1': metrics['macro_f1'],
            'per_class_f1': metrics['per_class_f1'],
            'confusion_matrix': metrics['confusion_matrix']
        }
    
    def save_results(self):
        """çµæœã‚’MLflowã‚„WandBã«ä¿å­˜"""
        pass
```

### A/Bãƒ†ã‚¹ãƒˆè¨­è¨ˆ
| å®Ÿé¨“ID | ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ | å¤‰æ›´ç‚¹ | æœŸå¾…åŠ¹æœ |
|--------|------------|--------|---------|
| exp002 | exp001 | äºŒæ®µéšåˆ†é¡ | Macro F1 +0.05 |
| exp003 | exp002 | SMOTE | Macro F1 +0.03 |
| exp004 | exp003 | Linear Acc | å…¨ä½“ +0.02 |
| exp005 | exp004 | æ·±å±¤å­¦ç¿’ | å…¨ä½“ +0.03 |

---

## ğŸš¦ ãƒªã‚¹ã‚¯ã¨å¯¾ç­–

### ãƒªã‚¹ã‚¯1: éå­¦ç¿’
**ç—‡çŠ¶:** CVé«˜ã€LBä½
**å¯¾ç­–:** 
- ã‚ˆã‚Šå¼·ã„æ­£å‰‡åŒ–
- ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆå¢—åŠ 
- ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ

### ãƒªã‚¹ã‚¯2: è¨ˆç®—æ™‚é–“
**ç—‡çŠ¶:** è¨“ç·´ãŒé…ã„
**å¯¾ç­–:**
- ç‰¹å¾´é‡å‰Šæ¸›
- ãƒ¢ãƒ‡ãƒ«è»½é‡åŒ–
- ä¸¦åˆ—å‡¦ç†

### ãƒªã‚¹ã‚¯3: ãƒ¡ãƒ¢ãƒªä¸è¶³
**ç—‡çŠ¶:** OOM ã‚¨ãƒ©ãƒ¼
**å¯¾ç­–:**
- ãƒãƒƒãƒå‡¦ç†
- ç‰¹å¾´é‡ã®æ®µéšçš„è¨ˆç®—
- float32 â†’ float16

---

## âœ… ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

### å®Ÿè£…å‰ã®ç¢ºèª
- [ ] ãƒ‡ãƒ¼ã‚¿ã®å“è³ªç¢ºèª
- [ ] ã‚¯ãƒ©ã‚¹åˆ†å¸ƒã®å¯è¦–åŒ–
- [ ] ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã®å†ç¾
- [ ] è©•ä¾¡æŒ‡æ¨™ã®ç†è§£

### å®Ÿè£…ä¸­ã®ç¢ºèª
- [ ] å˜ä½“ãƒ†ã‚¹ãƒˆã®ä½œæˆ
- [ ] ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã®ä¸€è²«æ€§
- [ ] ç‰¹å¾´é‡ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
- [ ] å†ç¾æ€§ã®ç¢ºä¿ï¼ˆseedå›ºå®šï¼‰

### å®Ÿè£…å¾Œã®ç¢ºèª
- [ ] éå­¦ç¿’ã®ãƒã‚§ãƒƒã‚¯
- [ ] æ¨è«–æ™‚é–“ã®æ¸¬å®š
- [ ] ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®ç¢ºèª
- [ ] æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼

---

## ğŸ“ å‚è€ƒå®Ÿè£…

### äºŒæ®µéšåˆ†é¡ã®æ ¸å¿ƒéƒ¨åˆ†
```python
class TwoStageClassifier:
    def predict_proba(self, X):
        # Stage 1: Binary prediction
        binary_proba = self.binary_model.predict_proba(X)
        
        # Initialize final probabilities
        final_proba = np.zeros((len(X), 18))
        
        # Stage 2: Conditional prediction
        for i in range(len(X)):
            if binary_proba[i, 1] > 0.5:  # BFRB
                bfrb_proba = self.bfrb_model.predict_proba(X[i:i+1])
                final_proba[i, :8] = binary_proba[i, 1] * bfrb_proba[0]
            else:  # Non-BFRB
                non_bfrb_proba = self.non_bfrb_model.predict_proba(X[i:i+1])
                final_proba[i, 8:] = binary_proba[i, 0] * non_bfrb_proba[0]
        
        return final_proba
```

### ã‚¯ãƒ©ã‚¹ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°ã®å®Ÿè£…
```python
def create_balanced_dataset(X, y):
    # BFRBã‚¯ãƒ©ã‚¹ã®åˆ†é›¢
    bfrb_indices = np.where(y < 8)[0]
    non_bfrb_indices = np.where(y >= 8)[0]
    
    # BFRBã‚¯ãƒ©ã‚¹ã®ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°
    X_bfrb = X[bfrb_indices]
    y_bfrb = y[bfrb_indices]
    
    # å„ã‚¯ãƒ©ã‚¹ã®ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’æƒãˆã‚‹
    max_samples = np.max(np.bincount(y_bfrb))
    balanced_indices = []
    
    for cls in range(8):
        cls_indices = np.where(y_bfrb == cls)[0]
        n_samples = len(cls_indices)
        
        if n_samples < max_samples:
            # ã‚ªãƒ¼ãƒãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
            additional = np.random.choice(cls_indices, 
                                        max_samples - n_samples,
                                        replace=True)
            cls_indices = np.concatenate([cls_indices, additional])
        
        balanced_indices.extend(cls_indices)
    
    # çµåˆ
    X_balanced = np.vstack([X_bfrb[balanced_indices], 
                           X[non_bfrb_indices]])
    y_balanced = np.concatenate([y_bfrb[balanced_indices],
                                y[non_bfrb_indices]])
    
    return X_balanced, y_balanced
```

---

## ğŸ¯ æˆåŠŸã®å®šç¾©

### çŸ­æœŸç›®æ¨™ï¼ˆ1é€±é–“ï¼‰
- âœ… Macro F1 > 0.52
- âœ… äºŒæ®µéšåˆ†é¡ã®å®Ÿè£…å®Œäº†
- âœ… ã‚¯ãƒ©ã‚¹ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°å®Œäº†

### ä¸­æœŸç›®æ¨™ï¼ˆ2é€±é–“ï¼‰
- â¬œ Macro F1 > 0.56
- â¬œ å…¨ä½“ã‚¹ã‚³ã‚¢ > 0.75
- â¬œ ç‰¹å¾´é‡æœ€é©åŒ–å®Œäº†

### é•·æœŸç›®æ¨™ï¼ˆ3é€±é–“ï¼‰
- â¬œ Macro F1 > 0.60
- â¬œ å…¨ä½“ã‚¹ã‚³ã‚¢ > 0.77
- â¬œ Top 20%é”æˆ

---

*Document Version: 1.0*  
*Created: 2025-01-13*  
*Next Review: 2025-01-20*