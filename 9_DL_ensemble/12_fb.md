ありがとうございます。貼っていただいたスクリプトを**端から端まで読み込み**、設計・安全性・速度・再現性・スコア改善の観点でレビューしました。結論から言うと、**前回系（把握できる範囲）からの改善点は多く、設計としてかなり堅牢**になっています。ただし、**実運用で即座に直すべき不具合が 2 点**、そして**スコア・安定性面で効く改善候補**がいくつかあります。以下、包括的に整理します。

---

## まず評価（ハイライト）

**良くなっている点（大きな改善）**

- **モダリティドロップアウト**（ToF/THM）を導入し、**テスト時の欠落に強い**特徴量を学習（LGBM 側）。
- **DL（PyTorch/Keras）と LGBM の 3 系統エン semble**＋**OOF を用いた重み最適化**（任意）を実装し、**堅牢性と上振れ余地**が増加。
- **四元数 → 世界座標 → 重力分離**の前処理が**NaN/短系列/非正規化**に対してフォールバック付きで堅牢。
- **フレーム特徴の LRU メモリキャッシュ**導入で、DL の学習/推論の**反復計算を大幅削減**。
- **StratifiedGroupKFold**（subject でグループ化）を全系（LGBM/torch/keras）で使い、**情報漏洩を抑制**。
- **ログとチェックポイント**の設計が細かい（JSONL 進捗・fold ごとの最良保存・OneCycleLR・AMP 対応など）。
- ToF/THM について**時系列要約＋（ToF は）8×8 空間特徴**まで踏み込み、\*\*IMU×ToF/THM の相関（xmod）\*\*まで拡張。
- Keras/Torch ともに**マスク伝搬**を MaxPool 回数に合わせて**正しくダウンサンプリング**しており、可変長パディングに**破綻がない**。

---

## 重要：**即修正が必要な不具合（2 点）**

1. **LGBM を学習しない場合の `feature_importance` 参照バグ**

   - `RUN_LGBM_TRAINING=False`（＝事前学習済み pkl を使う時）でも、`if RUN_ANY_TRAINING:` ブロックの末尾で

     ```python
     feature_importance = pd.DataFrame({
         "feature": X_train.columns,
         "importance": np.mean([m.feature_importances_ for m in models], axis=0),
     })
     ```

     が**無条件**に走り、`models` が未定義で **NameError**（または UnboundLocalError）。

   - **対処**：この処理を `if RUN_LGBM_TRAINING:` の内側へ移動、または `if RUN_LGBM_TRAINING and len(models)>0:` でガード。

   **最小差分（抜粋）**

   ```diff
   --- a/main() 末尾近辺
   -        # （任意）特徴量重要度の保存
   -        feature_importance = pd.DataFrame({
   -            "feature": X_train.columns,
   -            "importance": np.mean([m.feature_importances_ for m in models], axis=0),
   -        }).sort_values("importance", ascending=False)
   -        ...
   +        # （任意）特徴量重要度の保存（LGBM学習を実行したときのみ）
   +        if RUN_LGBM_TRAINING and len(models) > 0:
   +            feature_importance = pd.DataFrame({
   +                "feature": X_train.columns,
   +                "importance": np.mean([m.feature_importances_ for m in models], axis=0),
   +            }).sort_values("importance", ascending=False)
   +            print("\nTop 20 Most Important Features:")
   +            print(feature_importance.head(20))
   +            feature_importance.to_csv(
   +                os.path.join(Config.OUTPUT_PATH, "feature_importance.csv"), index=False
   +            )
   +            print("\n✓ LGBM Training complete!")
   ```

2. **Kaggle 上で“LGBM は事前 pkl、Torch/Keras は新規学習”シナリオの確認**

   - その場合でも上の修正を入れれば落ちませんが、**LGBM 学習用に抽出した巨大な `X_train` が不要**になります。
   - 実際に Torch/Keras のみ学習する場合は、高次の特徴量抽出（`extract_features` → 表形式の `X_train`）は不要で、**DL 系はフレーム特徴（`build_frame_features`）のみ**で完結します。
   - **対処（任意）**：

     - `RUN_LGBM_TRAINING` が False なら **高次特徴量抽出パイプをスキップ**して I/O/時間を削減（ただし DL 側はそのまま）。
     - 既に多数のログやキャッシュが絡むため、まずは**上記バグ修正だけ**でも安定運用可能です。

---

## 安定性・速度・再現性：よい点と改善提案

### ✅ すでに良い点

- **np/scipy 例外保護**が徹底（filtfilt 失敗 →median、PSD 短系列 →0 埋め等）。
- **四元数の符号連続性補正**（`fix_quaternion_sign`）で角速度算出の安定性を確保。
- **Keras AMP 切替**（環境変数）など**Kaggle 実行時の事故を抑制**。
- **`NUM_WORKERS=0` 既定**でワーカ問題の回避（Kaggle ノートブックでありがちな停止に有効）。

### 🔧 改善提案（実装容易＆効果が出やすい順）

1. **DL 学習にもモダリティドロップアウトを導入**（現状 LGBM のみ）

   - たとえばフレーム特徴の ToF/THM 列（`tof_*`, `thm_*`）に対して**バッチ単位で確率的にゼロ化**。
   - Torch: `TorchDataset.__getitem__` で `if train_mode:` の分岐を作り、列マスク適用。
   - Keras: `to_xy` 変換時に同様。
     → **テスト時に ToF/THM が欠落/劣化しても崩れにくく**。

2. **不均衡対策**

   - LGBM: `class_weight` を `balanced` もしくはクラス頻度逆数で指定。
   - Torch/Keras: **focal loss**（または `pos_weight`／Weighted CE）を導入。
     → **マイナークラス（BFRB 内の稀クラス）F1 の底上げ**が期待できます。
     （Torch の`soft_ce_loss`はラベルスムージングのみ。Focal に置換するだけで効果が出やすいです）

3. **LGBM の早期打ち切り指標を目的指標寄りに**

   - 現在 `multi_logloss` で EarlyStopping していますが、評価は **Binary F1 と BFRB 内 Macro F1 の平均**。
   - `LGBMClassifier` ラッパーはカスタム `feval` を直接渡しづらいので、**`lgb.train` に切替**して `feval`（バリデの F1 を返す）で早期停止すると**CV スコアの相関が上がりやすい**です。
   - 代替として `eval_metric` に `multi_error` 追加や、**OOF 最良 epoch での推定**を保存して使う、等も有効。

4. **Keras/Torch で F1 メトリクスをログ**

   - Keras: `tf.numpy_function` で `macro_f1` / `binary_f1` を算出・記録（早期停止は依然 `val_loss`でも、学習挙動の把握が楽）。
   - Torch: 既に検証時に出しているので、**CSV にも保存**（既に JSONL 出力あり。CSVLogger を併用すると分析しやすい）。

5. **推論時の安定化（確率の温度/クリッピング）**

   - エン semble 前に各モデル出力を**温度スケーリング**（固定温度でも可）→**過信を抑える**。
   - **クラスごとの最小確率を ε で底上げ**後に再正規化。
     → **微小ノイズによる argmax 反転**を抑え、外れ値耐性が上がります。

6. **学習・推論速度の追加最適化**

   - Welch の `nperseg` は短系列時に**かなり小さく**なり得ます。`max(32, min(64, ...))` のように**下限を 32 程度**に固定すると SNR が向上しやすい（速度はほぼ変わらず）。
   - `FrameFeatureCache` は RAM を圧迫しうるため、**OOM 時に `MAX_MB` を環境変数で迅速に下げる**チューニングを README へ明記。

7. **乱数の徹底固定**

   - Torch は固定済み、Keras も `tf.random.set_seed` 済み。さらに**Python/NumPy/OS 環境変数**も念のため固定（`PYTHONHASHSEED` 等）。
   - 既にほぼ再現可能ですが、**小数点以下の差が問題になる時**の備えに。

---

## 特徴量・信号処理まわりの所感

- **四元数の欠損補完**→**正規化**→**符号連続補正**→**角速度**は良い流れ。
- **重力分離**はデフォルト LPF で 0.75Hz、短い場合は median にフォールバック：BFRB の\*\*記号的な動き（1–3Hz）\*\*を狙う帯域分離として妥当。
- **ピーク、自己相関、勾配ヒストグラム、Welch-PSD、エントロピー**など、**多面的な要約**が揃っており、LGBM に相性が良い。
- **ToF 8×8 空間特徴**（重心/二次モーメント/左右上下非対称）は、頭部や顔周りの近接挙動を**姿勢非依存に取り出す**のに有効。
- **xmod 相関**（IMU×ToF/THM）は分布が崩れやすいので、**NaN→0 の処理**と**相関長の確保**が肝心。実装はガードされており OK。

**欲張りすぎない追加案（任意）**

- **線形加速度の持続性/停止性**を測るための**ランレングス統計**（しきい値上/下の連続長の平均・分散）。
- **角速度 vs 直線加速度**の**相位相性**（クロススペクトルの位相、あるいは帯域ごとのコヒーレンス簡易指標）。
- **ToF/THM の時間異常比率**（例：min/median や hotspot が一定閾値を超えるフレーム割合）。

---

## エン semble の設計について

- 既定の重み `LGBM:0.20 / Torch:0.45 / Keras:0.35` は妥当。
- **OOF 最適化**があるので、**学習が回る環境なら最終的には最適重みを採用**するのがよいです（`ensemble/weights.json` を推論時に読み込むフラグを追加して自動適用するのも ◎）。
- **モジュール不在時の重み正規化**（すでに実装済み）で実運用の頑強性も OK。

---

## コード品質・保守性

- **ログ/状態 JSON の意味が明確**で使い勝手が良いです。
- **列順固定（`feature_order`）とアライメント**は推論事故の元を潰せていて Good。
- `ModelPaths` を**単一の真実の源泉**（SOT）にしているのも正解。
- 些細ですが、未使用変数/関数（例：`joblib_hash`）は**lint で弾いて**おくと読みやすくなります。

---

## 追加の最小パッチ（効果大・変更小）

### 1) Torch で focal loss を切替可能に

```python
def focal_loss(logits, targets, alpha=0.25, gamma=2.0, n_classes=18):
    p = torch.softmax(logits, dim=1)
    y = F.one_hot(targets, n_classes).float()
    pt = (p * y).sum(dim=1).clamp_min(1e-8)
    loss = -alpha * (1 - pt)**gamma * torch.log(pt)
    return loss.mean()
```

学習ループで `soft_ce_loss` と切替できるよう環境変数でスイッチ。

### 2) Keras で class_weight を有効化（簡易）

`model.fit(..., class_weight=class_weight_dict)` を付与。`class_weight_dict` は学習 fold のラベル頻度から作成。
→ ラベルスムージングと相性良好。過学習もしにくいです。

### 3) 短系列での Welch 安定化

```diff
- nperseg = min(64, len(data) // 4, len(data))
+ nperseg = max(32, min(64, len(data) // 4, len(data)))
```

ごく短い時に PSD が不安定化するのを緩和。

### 4) エン semble の温度スケーリング（固定値）

```python
def _t(x, T=1.5):  # 1.2～2.0で軽くチューニング
    x = np.log(np.clip(x, 1e-8, 1.0))
    x = x / T
    x = np.exp(x - x.max())  # 安定化
    return x / x.sum()
# final_proba = 和の前に各モデルに _t() をかける
```

過信を抑え、argmax のブレを低減。

---

## 期待される影響（概算）

- **バグ修正**：学習/推論フローが**確実に最後まで走る**（LGBM 事前 pkl ＋ Torch/Keras 学習ケース）。
- **DL へのモダリティドロップアウト**：**公開 LB が安定**（ToF/THM の欠落やノイズに強く）。
- **不均衡対策（focal/weight）**：**マイナークラスの F1 改善**。
- **目的指標寄りの EarlyStopping**：CV と LB の**相関改善 → LB の伸び**。
- **温度スケーリング**：**予測の一貫性**向上、細かい逆転ミスの減少。

---

## まとめ

- **全体としては明確に「改善されています」**。

  - データ前処理の堅牢化、DL ＋ LGBM のエン semble、キャッシュとログ基盤、ToF/THM の扱いなど、実戦向きの配慮が行き届いています。

- ただし、**LGBM 未学習時の feature_importance 参照バグ**は**即修正**してください。
- その上で、**DL 側にもモダリティドロップアウト**と**不均衡対策**、**EarlyStopping の目的指標合わせ**を入れると、**スコアと再現性の両方**がさらに伸びるはずです。

必要であれば、上記のパッチを当てた**最小改変版**や、**LGBM の`lgb.train`移行＋ F1 feval**のサンプルもまとめてお渡しできます。
