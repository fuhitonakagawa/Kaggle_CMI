了解です。
**目的**は「**グローバル変数でモデル pkl のパスを指定できるようにし、None なら従来通り学習→保存、パス指定があれば学習をスキップしてそのモデルを使う**」。さらに **サブミッションでは “推論サーバー起動 → 特徴量前処理 → 学習済みモデルで推論”** を確実に実行できる構成に直します。

以下、\*\*やること（タスク分解） → 変更ポイント → 具体的な実装手順（貼り付けコード付き）\*\*の順でまとめます。
**最小変更**で安全に動くように、既存ノートブックの流れはなるべく崩しません。

---

## タスク分解（やること一覧）

1. **Config にグローバル変数を追加**

   * `MODEL_PATH` を追加（`None` なら学習、文字列パスならそれを使用）。
   * ついでに保存ファイル名 `MODEL_FILENAME` を定義。
   * （任意）環境変数 `MODEL_PATH` で上書きできるようにする。

2. **学習パートをガードしてスキップ可能化**

   * `RUN_TRAINING = Config.MODEL_PATH is None` で分岐。
   * 学習したら `RUNTIME_MODEL_PATH` に保存先パスを入れる。
   * スキップ時は `RUNTIME_MODEL_PATH = Config.MODEL_PATH` にする。
   * ※トレーニング用の **訓練データ読込・特徴量抽出** もこのフラグでガードし、**モデル使用時は一切実行しない**（推論だけに集中）。

3. **モデル保存と読込のユーティリティ関数を追加**

   * `save_model_bundle(...) -> str`：モデル束とメタを pkl に保存してパス返却。
   * 読込は既存の `joblib.load` をそのまま使う。

4. **特徴量抽出関数の重複を解消**

   * ノートブック後半に**同名の `extract_features` が再定義**されています。**1つに統一**し、**推論時の列合わせ**は**小さなヘルパー** `align_features_for_inference(df, feature_names)` を追加して対応します。

5. **推論初期化**

   * `model_data = joblib.load(RUNTIME_MODEL_PATH)` で読み込み、
     `models / feature_names / reverse_gesture_mapper / fold_weights` を **グローバルに保持**。
   * `predict()` 内では
     `raw = extract_features(...) → X = align_features_for_inference(raw, feature_names)`
     で**学習時と同じ列順**に合わせてから `predict_proba`。

6. **CMI Inference Server の起動**

   * 既存の `CMIInferenceServer(predict)` を流用。
   * **学習スキップ時でも即起動**できるよう、**初期化順**を整理。

7. **（任意）動作チェック**

   * ダミーのシーケンスで `predict()` を一度呼ぶ。

---

## 変更点（どこをどう変えるか）

> 下のコードブロックを **順番通りに** 既存ノートブックへ貼り込み/置換してください。
> 「ADD」は**追加**、「REPLACE」は**既存を置換**です。

---

### 1) Config にグローバル変数を追加（ADD / 先頭の Config 定義内）

```python
# === ADD: Model selection ===
# If None -> train and save; If str(path) -> skip training and use this model bundle
MODEL_PATH = os.getenv("MODEL_PATH", None)  # e.g. "/kaggle/input/my-model/imu_lgbm_model.pkl"
MODEL_FILENAME = "imu_lgbm_model.pkl"       # filename when we save after training
```

> これで **環境変数 `MODEL_PATH`** でも指定可能になります（Kaggle の「Add-ons → Secrets」等で指定可）。

---

### 2) モデル保存ユーティリティを追加（ADD / 学習パートより**前**の任意のセル）

```python
# === ADD: Save model bundle helper ===
def save_model_bundle(models, X_train, cv_scores, output_dir: str, filename: str) -> str:
    # Normalize fold weights（ゼロ除算対策）
    denom = max(float(np.sum(cv_scores)), 1e-12)
    fold_weights = np.array(cv_scores) / denom

    model_data = {
        "models": models,
        "feature_names": list(X_train.columns),
        "gesture_mapper": GESTURE_MAPPER,
        "reverse_gesture_mapper": REVERSE_GESTURE_MAPPER,
        "cv_scores": cv_scores,
        "fold_weights": fold_weights.tolist(),
        "mean_cv_score": float(np.mean(cv_scores)) if len(cv_scores) else 0.0,
        "config": {
            "n_folds": Config.N_FOLDS,
            "seed": Config.SEED,
            "lgbm_params": Config.LGBM_PARAMS,
        },
    }

    os.makedirs(output_dir, exist_ok=True)
    out_path = os.path.join(output_dir, filename)
    joblib.dump(model_data, out_path)
    print(f"✓ Models saved to {out_path}")
    print(f"✓ File size: {os.path.getsize(out_path) / 1024 / 1024:.2f} MB")
    return out_path
```

---

### 3) 特徴量抽出関数の**重複を解消**（REPLACE）

ノートブック後半にもう一度 `extract_features` を定義している箇所を**削除**し、以下の**小ヘルパー**だけを追加してください。
（= 前半の `extract_features` を**唯一の定義**として残します）

```python
# === ADD: Align helper for inference (use training-time columns in the same order) ===
def align_features_for_inference(result_df: pd.DataFrame, feature_names: list) -> pd.DataFrame:
    for col in feature_names:
        if col not in result_df.columns:
            result_df[col] = 0
    # extra cols are dropped by selecting in order
    result_df = result_df[feature_names]
    return result_df.fillna(0)
```

> 以降、`predict()` では `extract_features()`（前半で定義済）を呼び、**ここで列合わせ**を行います。

---

### 4) 学習パートをガード（REPLACE / 「Loading training data…」以降の学習ブロック一式）

学習データの読込〜特徴量抽出〜CV 学習〜保存まで**全体**を以下に置換してください。
（`RUN_TRAINING` で判定、**スキップ時は一切実行しない**）

```python
# === REPLACE: Training block guarded by MODEL_PATH ===
RUNTIME_MODEL_PATH = None
RUN_TRAINING = (Config.MODEL_PATH is None)

if RUN_TRAINING:
    # ------------------ LOAD TRAIN DATA ------------------
    print("Loading training data...")
    train_df = pl.read_csv(Config.TRAIN_PATH)
    train_demographics = pl.read_csv(Config.TRAIN_DEMOGRAPHICS_PATH)

    print(f"✓ Train shape: {train_df.shape}")
    print(f"✓ Demographics shape: {train_demographics.shape}")

    imu_cols = ["sequence_id", "subject", "phase", "gesture"] + Config.ACC_COLS + Config.ROT_COLS
    print(f"✓ Using {len(imu_cols)} IMU columns")

    # ------------------ FEATURE EXTRACTION ------------------
    print("Extracting features for training sequences...")
    train_features_list = []
    train_labels = []
    train_subjects = []

    unique_sequences = train_df["sequence_id"].unique()
    n_sequences = len(unique_sequences)
    print(f"Total sequences to process: {n_sequences}")

    train_sequences = train_df.select(pl.col(imu_cols)).group_by("sequence_id", maintain_order=True)

    for i, (sequence_id, sequence_data) in enumerate(train_sequences):
        if i % 1000 == 0:
            print(f"Processing sequence {i + 1}/{n_sequences}")

        seq_id_val = sequence_id[0] if isinstance(sequence_id, tuple) else sequence_id

        subject_id = sequence_data["subject"][0]
        subject_demographics = train_demographics.filter(pl.col("subject") == subject_id)

        # 前半で定義済みの extract_features() を使用（重複定義は削除済み）
        features = extract_features(sequence_data, subject_demographics)
        train_features_list.append(features)

        gesture = sequence_data["gesture"][0]
        label = GESTURE_MAPPER[gesture]
        train_labels.append(label)
        train_subjects.append(subject_id)

    assert len(train_features_list) == n_sequences, \
        f"Feature extraction failed: {len(train_features_list)} != {n_sequences}"
    print(f"✓ Successfully processed all {n_sequences} sequences")

    X_train = pd.concat(train_features_list, ignore_index=True)
    y_train = np.array(train_labels)
    subjects = np.array(train_subjects)

    print(f"✓ Features extracted: {X_train.shape}")
    print(f"✓ Number of classes: {len(np.unique(y_train))}")

    # ------------------ CV TRAINING ------------------
    print("Training LightGBM models with cross-validation...")

    cv = StratifiedGroupKFold(n_splits=Config.N_FOLDS, shuffle=True, random_state=Config.SEED)
    models = []
    oof_predictions = np.zeros(len(y_train))
    cv_scores = []

    for fold, (train_idx, val_idx) in enumerate(cv.split(X_train, y_train, subjects)):
        print(f"\n--- Fold {fold + 1}/{Config.N_FOLDS} ---")

        X_fold_train = X_train.iloc[train_idx]
        X_fold_val   = X_train.iloc[val_idx]
        y_fold_train = y_train[train_idx]
        y_fold_val   = y_train[val_idx]

        print(f"Train size: {len(X_fold_train)}, Val size: {len(X_fold_val)}")

        model = LGBMClassifier(**Config.LGBM_PARAMS)
        model.fit(
            X_fold_train, y_fold_train,
            eval_set=[(X_fold_val, y_fold_val)],
            eval_names=["valid"],
            eval_metric="multi_logloss",
            callbacks=[log_evaluation(period=50), early_stopping(stopping_rounds=100, verbose=True)],
        )

        models.append(model)

        val_preds = model.predict(X_fold_val)
        oof_predictions[val_idx] = val_preds

        binary_f1 = f1_score(
            np.where(y_fold_val <= 7, 1, 0),
            np.where(val_preds   <= 7, 1, 0),
            zero_division=0.0,
        )
        macro_f1 = f1_score(
            np.where(y_fold_val <= 7, y_fold_val, 99),
            np.where(val_preds   <= 7, val_preds, 99),
            average="macro", zero_division=0.0,
        )

        score = 0.5 * (binary_f1 + macro_f1)
        cv_scores.append(score)

        print(f"Fold {fold + 1} Score: {score:.4f} (Binary F1: {binary_f1:.4f}, Macro F1: {macro_f1:.4f})")

    print("\n✓ Cross-validation complete!")
    print(f"Overall CV Score: {np.mean(cv_scores):.4f} ± {np.std(cv_scores):.4f}")

    # ------------------ SAVE MODEL BUNDLE ------------------
    RUNTIME_MODEL_PATH = save_model_bundle(
        models=models,
        X_train=X_train,
        cv_scores=cv_scores,
        output_dir=Config.OUTPUT_PATH,
        filename=Config.MODEL_FILENAME,
    )

    # （任意）特徴量重要度の保存
    feature_importance = pd.DataFrame({
        "feature": X_train.columns,
        "importance": np.mean([m.feature_importances_ for m in models], axis=0),
    }).sort_values("importance", ascending=False)
    print("\nTop 20 Most Important Features:")
    print(feature_importance.head(20))
    feature_importance.to_csv(os.path.join(Config.OUTPUT_PATH, "feature_importance.csv"), index=False)
    print("\n✓ Training complete!")

else:
    # ------------------ SKIP TRAINING ------------------
    RUNTIME_MODEL_PATH = Config.MODEL_PATH
    print(f"✓ Skipping training. Using pretrained model at: {RUNTIME_MODEL_PATH}")
    if not os.path.exists(RUNTIME_MODEL_PATH):
        raise FileNotFoundError(
            f"Specified MODEL_PATH does not exist: {RUNTIME_MODEL_PATH}\n"
            f"Upload your pkl to a Kaggle dataset and set the absolute path."
        )
```

---

### 5) モデル読込と推論初期化（REPLACE / 既存の「Loading trained model...」以降）

下記に置き換えます。**ハードコードのパス**（`/kaggle/working/imu_lgbm_model.pkl`）は**使用しません**。
学習した場合も、スキップした場合も、**`RUNTIME_MODEL_PATH`** からロードします。

```python
# === REPLACE: Load model bundle for inference ===
print("Loading model bundle for inference...")
model_data = joblib.load(RUNTIME_MODEL_PATH)

models = model_data["models"]
feature_names = model_data["feature_names"]
reverse_gesture_mapper = model_data["reverse_gesture_mapper"]

if "fold_weights" in model_data and len(model_data["fold_weights"]) == len(models):
    fold_weights = np.array(model_data["fold_weights"])
    print(f"✓ Using fold weights: {fold_weights}")
else:
    fold_weights = np.ones(len(models)) / max(len(models), 1)
    print("✓ Using equal weights (no fold weights found)")

print(f"✓ Loaded {len(models)} models")
print(f"✓ Number of features: {len(feature_names)}")
if "mean_cv_score" in model_data:
    print(f"✓ CV Score (recorded): {model_data['mean_cv_score']:.4f}")
```

---

### 6) `predict()` を**唯一の `extract_features`**＋**列合わせヘルパー**で動かす（REPLACE）

```python
# === REPLACE: Prediction function ===
def predict(sequence: pl.DataFrame, demographics: pl.DataFrame) -> str:
    """
    Prediction function for CMI inference server.
    Takes a single sequence and returns the predicted gesture name.
    """
    try:
        # 1) Feature extraction (the single, unified function defined earlier)
        raw_features = extract_features(sequence, demographics)

        # 2) Align to training-time feature columns (order & presence)
        X = align_features_for_inference(raw_features, feature_names)

        # 3) Weighted-ensemble prediction
        proba_accum = np.zeros(len(reverse_gesture_mapper))
        for i, model in enumerate(models):
            pred_proba = model.predict_proba(X)[0]
            proba_accum += pred_proba * fold_weights[i]

        final_class = int(np.argmax(proba_accum))
        gesture_name = reverse_gesture_mapper[final_class]
        return gesture_name

    except Exception as e:
        print(f"Prediction error: {e}")
        return "Text on phone"
```

---

### 7) （任意）ダミー推論テスト（ADD / predict 定義の直後で OK）

```python
# === ADD: quick sanity test ===
print("Testing prediction function with dummy data...")
test_sequence = pl.DataFrame(
    {
        "acc_x": np.random.randn(120),
        "acc_y": np.random.randn(120),
        "acc_z": np.random.randn(120),
        "rot_w": np.random.randn(120),
        "rot_x": np.random.randn(120),
        "rot_y": np.random.randn(120),
        "rot_z": np.random.randn(120),
    }
)
test_demographics = pl.DataFrame(
    {"age":[25], "adult_child":[1], "sex":[0], "handedness":[1], "height_cm":[170],
     "shoulder_to_wrist_cm":[50], "elbow_to_wrist_cm":[30]}
)
print(f"✓ Test prediction: {predict(test_sequence, test_demographics)}")
```

---

### 8) 推論サーバーの起動（KEEP/微修正）

既存のサーバー起動セルはそのままで構いません（`predict` が上記に差し替わっていれば OK）。

```python
# Import the CMI inference server
sys.path.append("/kaggle/input/cmi-detect-behavior-with-sensor-data")

# Initialize CMI inference server
print("Initializing CMI inference server...")
inference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict)
print("✓ Inference server initialized")

# Run inference based on environment
print("Starting inference...")
if os.getenv("KAGGLE_IS_COMPETITION_RERUN"):
    print("Running in competition environment...")
    inference_server.serve()
else:
    print("Running in local testing mode...")
    inference_server.run_local_gateway(
        data_paths=(
            "/kaggle/input/cmi-detect-behavior-with-sensor-data/test.csv",
            "/kaggle/input/cmi-detect-behavior-with-sensor-data/test_demographics.csv",
        )
    )
    print("\n✓ Inference complete!")
    print("✓ submission.parquet has been generated")
```

---

## 実装計画（手順まとめ）

1. **Config** に `MODEL_PATH` と `MODEL_FILENAME` を追加。

   * 例：**学習して使う** → `MODEL_PATH = None`（デフォルト）。
   * 例：**既存モデルを使う** → `MODEL_PATH = "/kaggle/input/your-dataset/imu_lgbm_model.pkl"`
     （または Kaggle の環境変数 `MODEL_PATH` に設定）。

2. **学習ブロックをガード**して、`MODEL_PATH is None` のときだけ

   * 訓練データ読込 → 特徴量抽出（前半の `extract_features` 使用）
     → 5-fold CV 学習 → `save_model_bundle(...)` で保存
     → `RUNTIME_MODEL_PATH` に保存先をセット。

3. **推論初期化**：

   * `model_data = joblib.load(RUNTIME_MODEL_PATH)`
   * `models / feature_names / reverse_gesture_mapper / fold_weights` を取り出す。
   * **重複定義の `extract_features` は削除**し、**列合わせ**は `align_features_for_inference()` で行う。

4. **predict()**：

   * `extract_features()` → `align_features_for_inference()` → 各 fold の `predict_proba` を `fold_weights` で加重平均 → 予測クラスを**ラベル名**に戻す。

5. **CMI サーバー起動**：

   * 既存通り、`CMIInferenceServer(predict)` を起動。
   * サブミッション環境では `serve()` が呼ばれ、**推論のみ**が走る。

---

## 使い方（運用）

* **学習して提出**（デフォルト）

  * `MODEL_PATH = None` のまま実行。
  * ノートブック内で学習→保存→そのまま**保存直後のモデル**で推論サーバー起動。

* **学習済みモデルを使う提出**

  1. 事前に学習済み `imu_lgbm_model.pkl` を **Kaggle Dataset** としてアップロード。
  2. ノートブック冒頭の `MODEL_PATH` をその pkl の**絶対パス**に設定
     例：`MODEL_PATH = "/kaggle/input/my-bfrb-lgbm/imu_lgbm_model.pkl"`
     （or 環境変数 `MODEL_PATH` に設定）
  3. 実行すると**学習はスキップ**され、すぐ**推論サーバー**が立ち上がる。

---

## よくある落とし穴と対処

* **extract\_features の二重定義**：必ず**1つに統一**してください。推論側では**列合わせヘルパー**だけ追加します。
* **列不一致**：`align_features_for_inference()` が**学習時の列順**に強制整列し、欠損列は 0 埋めします。
* **MODEL\_PATH の未存在**：ファイル存在チェックを入れているので、**パスが間違っていれば即エラー**にします。
* **学習スキップ時の高速化**：学習データ読込・前処理は**完全にスキップ**されるため、提出時の**タイムアウト回避**に有効です。

---

以上です。
この計画どおりに貼り替えれば、**1つのノートブックで「学習 or 既存モデル利用」を切り替え**、\*\*サブミッション要件（推論サーバー＋前処理＋学習済みモデル推論）\*\*を満たせます。
