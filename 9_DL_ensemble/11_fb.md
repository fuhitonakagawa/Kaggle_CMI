

## TL;DR（最重要の改善ポイント）

1. **実行順序のバグ**：`RUNTIME_MODEL_PATH` を `main()` 実行前に参照しており、**即時クラッシュ**します。推論ブートストラップは `main()` の後に移動/遅延ロードしてください（パッチあり）。
2. **学習データの shape 出力位置**：`RUN_ANY_TRAINING=False` 時でも `train_df` を参照してしまうため **NameError**。ログ出力を if ブロック内に移動（パッチあり）。
3. **MODEL_PATH の判定ロジック**：`candidate` 参照前に定義されない可能性があり **例外**。分岐を整理（パッチあり）。
4. **OOF を使う重み最適化が壊れる**：Torch/Keras で「既存重みがあるからスキップ」時に **OOF を埋めていない**。スキップ時も検証セットに対して推論し OOF を作成（パッチあり）。
5. **`apply_modality_dropout`** が行単位ループで遅い。**ベクトル化**で高速化（パッチあり）。
6. **RNN がパディングも計算**：LSTM/GRU がマスク未対応のため **無駄計算**。`pack_padded_sequence`（PyTorch）と `tf.ragged`/`masking`（Keras）でパディング部分をスキップ（パッチ例あり）。
7. **Welch の PSD 計算が多重**：周波数特徴を多数の系列に対して大きい `nperseg` で繰り返しており **重い**。`nperseg` を短縮（64 など）＋必要最小のチャネルに限定して **2 ～ 3 倍高速化**（通常ほぼ無劣化）。
8. **LightGBM の早期終了**：`early_stopping(100)` はやや長い。`stopping_rounds=50` + `subsample_freq=1` を追加すると **学習が短縮**（精度は概ね維持）。

---

## 1) ブロッカー（即修正を推奨）

### A. `RUNTIME_MODEL_PATH` を未定義のままロード

- 現状：`main()` 定義後すぐに

  ```python
  print("Loading model bundle for inference...")
  model_data = joblib.load(RUNTIME_MODEL_PATH)
  ```

  としており、`RUNTIME_MODEL_PATH` が未設定で **確実に例外**になります。

**対処**：推論用のロードは `main()` が `RUNTIME_MODEL_PATH` を確定した**後**に実行する。かつ、**遅延ロード**にして `predict()` の初回呼び出し時にロードしても OK。

> 下の「具体的パッチ」に安全なブートストラップ案を載せています。

---

### B. `RUN_ANY_TRAINING` が False でも `train_df.shape` を参照

- `if RUN_ANY_TRAINING:` ブロックの外で `train_df.shape` を出力しており、未定義参照で **NameError**。

**対処**：shape ログはブロック内に移動。

---

### C. MODEL_PATH 判定ロジックの例外

- `candidate` が未定義のまま `os.path.exists(candidate)` を呼ぶ分岐があります。

**対処**：`os.path.isdir(path)` の内外で分岐を完結させる（パッチ参照）。

---

## 2) 潜在的な問題・境界条件

- **OOF の欠落**（Torch/Keras スキップ時）：すでにベスト重みが存在して fold をスキップすると、OOF を入れずに進むため、**アンサンブル最適化が不安定**になります（`oof_*_proba.npy` に fold の穴が空く）。→ スキップ時も fold の検証分割を再生成して**推論だけ**行い OOF を埋めるべき。
- **Keras の学習率ログ**：`ProgressCallback` で `self.model.optimizer.lr` を参照していますが、バージョンによっては `learning_rate` 属性なことがあるため 0 になる可能性。→ `getattr(opt, "lr", getattr(opt, "learning_rate", 0.0))` の順で取得。
- **RNN でマスク未使用**（PyTorch/Keras とも）：Attention の手前で downsample した mask は使っていますが、RNN 自体が **pad 部分も計算**してしまい無駄が多い（速度・若干の数値影響）。→ packed sequence / ragged + Masking 対応が望ましい。
- **複数箇所で `make_keras_tensor` を定義**：重複（関数が二つ）。片方に統一を。
- **特徴量の大量生成**：Welch を 7 ～ 10 系列に対して重ねる設計は重い。しかも LGBM 側で上位 100 ～ 300 特徴に寄る傾向が強いので、**冗長**になりがち。
- **グローバル変数の初期化タイミング**：`reverse_gesture_mapper` など、推論ブート後にのみ有効なグローバルを前提にしている。遅延ロード前提に組み替えると安全。

---

## 3) 冗長・整理できる箇所

- `make_keras_tensor` が重複。**1 箇所に統一**して import 先でも使えるように。
- `FRAME_CACHE` の `joblib_hash` は未使用。不要なら削除。
- `KerasSpeedConfig.MIXED_PRECISION` の説明はあるがデフォルト無効。高速化目的なら**有効化を推奨**（出力層のみ float32 で既に対処済み）。

---

## 4) 精度を落とさずに高速化（具体策と理由）

### 4-1. 周波数特徴の高速化（大きな効果）

- **今**：`extract_frequency_features()` で `nperseg = min(128, len(data)//4, len(data))`。
  **提案**：

  - `nperseg = min(64, len(data)//4, len(data))` に短縮（典型的な 20Hz サンプリング + 数秒系列では十分）。
  - 頻度帯はそのまま（0.3–3 / 3–8 / 8–12 Hz）で OK。
  - さらに「**個別軸**（`world_acc_{x,y,z}`）」の周波数特徴は重複度が高いので、**まずは magnitude 系のみ**に限定して学習（`feature_importance` で不要なら再計算しない）
    → 体感で **2 ～ 3 倍** の前処理短縮が狙え、スコアへの影響は軽微なことが多いです。

### 4-2. `apply_modality_dropout` のベクトル化（中〜大）

- 行ごとの for ループをやめ、**ブールインデックス一括代入**にする（パッチあり）。fold ごとに 10〜50ms 程度の差でも、全 fold で効きます。

### 4-3. PyTorch：RNN のパディング計算をスキップ（中）

- `pack_padded_sequence` / `pad_packed_sequence` を用い、**有効長のみ RNN 計算**。Attention も mask で整合。推論も軽くなります。精度は通常変わりません（むしろ安定することも）。

### 4-4. Keras：mixed precision + mask 伝搬（中）

- すでに mixed precision の準備があり、出力層 dtype も float32 なので **安全に有効化**可能です（`KERAS_MP=1`）。
- `Masking` レイヤ、または `sample_weight` を使って **pad を損失から除外**。LSTM/GRU 入力に `mask` を通すことで無駄計算を抑制できます。

### 4-5. LightGBM：より速い早期終了（小〜中）

- `early_stopping(stopping_rounds=50)` に短縮 + `subsample_freq=1` 追加。
- 併せて `max_depth=7` / `num_leaves` をデータに合わせて微調整。多くのケースで **同等スコア**で収束が早まります。

### 4-6. 特徴量選別のオフライン化（任意・大）

- 既存の `feature_importance.csv` を用い、**上位 300〜500 特徴**のみに絞ると LGBM の学習は顕著に速くなります。
- 一度 importance を出したら、次回はその列サブセットで `X_train` を生成（正規化・検証は変えない）。この運用は精度影響がほぼないことが多い。

---

## 5) ロバスト化・再現性

- 乱数シード：PyTorch は設定済み。Keras も `tf.random.set_seed` 済み。**NumPy** も `np.random.seed(Config.SEED)` で統一済みで OK。
- ログ：JSONL を fold/epoch 単位で出しているのは良い設計。Keras の学習率の取得だけ互換取得（上）に変更。
- 例外メッセージ：MODEL_PATH 周りの FileNotFound に「Kaggle データセットにアップロードして絶対パスを…」が含まれており親切。分岐のバグを直せば十分。

---

## 6) 具体的パッチ（差分例）

### 6-1. 推論ブートストラップを `main()` 後に遅延ロード

```python
# ====== 推論バンドルの遅延ロード用ステート ======
class _InferState:
    def __init__(self):
        self.lgbm_models = None
        self.feature_names = None
        self.reverse_gesture_mapper = None
        self.fold_weights = None

INFER = _InferState()

def _load_lgbm_bundle(path):
    if INFER.lgbm_models is not None:
        return
    md = joblib.load(path)
    INFER.lgbm_models = md["models"]
    INFER.feature_names = md["feature_names"]
    INFER.reverse_gesture_mapper = md["reverse_gesture_mapper"]
    fw = md.get("fold_weights")
    INFER.fold_weights = np.array(fw) if fw is not None else np.ones(len(INFER.lgbm_models))/len(INFER.lgbm_models)
    print(f"✓ Loaded {len(INFER.lgbm_models)} LGBM models for inference")

def predict_lgbm_proba(sequence: pl.DataFrame, demographics: pl.DataFrame) -> np.ndarray:
    _load_lgbm_bundle(RUNTIME_MODEL_PATH)
    raw = extract_features(sequence, demographics)
    X = align_features_for_inference(raw, INFER.feature_names)
    n_classes = len(INFER.reverse_gesture_mapper)
    acc = np.zeros(n_classes, dtype=np.float64)
    for w, model in zip(INFER.fold_weights, INFER.lgbm_models):
        p = model.predict_proba(X)[0]
        pf = np.zeros(n_classes, dtype=np.float64)
        for local_idx, cls_id in enumerate(model.classes_):
            pf[int(cls_id)] = p[local_idx]
        acc += w * pf
    s = acc.sum()
    return acc / s if s > 0 else acc

# --- ここまで関数のみ定義。ロードは main() 実行後に行う ---
```

```python
if __name__ == "__main__":
    main()  # ← ここで RUNTIME_MODEL_PATH が確定
    # LGBM は predict() 内の遅延ロードに任せて OK
    inference_server = cmi.CMIInferenceServer(predict)
    if os.getenv("KAGGLE_IS_COMPETITION_RERUN"):
        inference_server.serve()
    else:
        inference_server.run_local_gateway(
            data_paths=(
                "/kaggle/input/cmi-detect-behavior-with-sensor-data/test.csv",
                "/kaggle/input/cmi-detect-behavior-with-sensor-data/test_demographics.csv",
            )
        )
```

> これで「未定義の RUNTIME_MODEL_PATH」「import 時に副作用で走る」問題が解消されます。

---

### 6-2. `RUN_ANY_TRAINING` False のときに `train_df` を参照しない

```python
if RUN_ANY_TRAINING:
    print("Loading training data...")
    train_df = pl.read_csv(Config.TRAIN_PATH)
    train_demographics = pl.read_csv(Config.TRAIN_DEMOGRAPHICS_PATH)
    print(f"✓ Train shape: {train_df.shape}")
    print(f"✓ Demographics shape: {train_demographics.shape}")
else:
    train_df = None
    train_demographics = None
```

---

### 6-3. MODEL_PATH の分岐バグ修正（安全版）

```python
# --- SKIP ALL TRAINING ---
if not RUN_LGBM_TRAINING:
    path = Config.MODEL_PATH
    if os.path.isdir(path):
        candidate = os.path.join(path, Config.MODEL_FILENAME)
        if not os.path.exists(candidate):
            raise FileNotFoundError(
                f"MODEL_PATH is a directory but {Config.MODEL_FILENAME} not found: {candidate}"
            )
        RUNTIME_MODEL_PATH = candidate
    else:
        if not os.path.exists(path):
            raise FileNotFoundError(f"Specified MODEL_PATH does not exist: {path}")
        RUNTIME_MODEL_PATH = path
    print(f"✓ Using pretrained LGBM at: {RUNTIME_MODEL_PATH}")
```

---

### 6-4. OOF をスキップ時も作る（Torch/Keras）

**Torch（スキップ分岐の直後に追記）**

```python
if CheckpointConfig.SKIP_TORCH_FOLD_IF_BEST_EXISTS and os.path.exists(best_path):
    ...
    # --- OOF だけ計算 ---
    ds_va = TorchDataset([seq_list[i] for i in va_idx], np.array(y_list)[va_idx],
                         scaler_stats, pad_len)
    dl_va = torch.utils.data.DataLoader(ds_va, batch_size=DLConfig.BATCH_SIZE,
                                        shuffle=False, num_workers=0,
                                        collate_fn=collate_batch)
    device = "cuda" if torch.cuda.is_available() else "cpu"
    ckpt = torch.load(best_path, map_location=device)
    model = TimeSeriesNet(ckpt["in_ch"], ckpt["n_classes"], hidden=128, dropout=DLConfig.DROPOUT)
    model.load_state_dict(ckpt["state_dict"], strict=True)
    model = model.to(device).eval()
    all_prob = []
    with torch.no_grad(), torch.cuda.amp.autocast(enabled=DLConfig.AMP):
        for xb, mb, yb in dl_va:
            prob = torch.softmax(model(xb.to(device), mb.to(device)), dim=1).cpu().numpy()
            all_prob.append(prob)
    oof_torch[va_idx] = np.concatenate(all_prob, axis=0)
    ...
```

**Keras（スキップ分岐の直後に追記）**

```python
if os.path.exists(weight_path) and CheckpointConfig.KERAS_EARLY_EXIT_IF_BEST_EXISTS:
    ...
    # --- OOF だけ計算 ---
    Xva, Mva, Yva = to_xy(va_idx)  # 既存の to_xy を再利用
    model = keras.models.load_model(weight_path, custom_objects={"KerasTemporalAttention": KerasTemporalAttention})
    proba_va = model.predict({"x": Xva, "mask": Mva}, batch_size=KerasConfig.BATCH_SIZE, verbose=0)
    oof_proba[va_idx] = proba_va
```

---

### 6-5. `apply_modality_dropout` のベクトル化

```python
def apply_modality_dropout(features_df: pd.DataFrame, dropout_prob: float = 0.5, seed: int | None = None) -> pd.DataFrame:
    rng = np.random.default_rng(seed)
    df = features_df.copy()
    n = len(df)
    drop_tof = rng.random(n) < dropout_prob
    drop_thm = rng.random(n) < dropout_prob

    tof_cols = [c for c in df.columns if c.startswith("tof_") and c != "mod_present_tof"]
    thm_cols = [c for c in df.columns if c.startswith("thm_") and c != "mod_present_thm"]
    xmod_tof = [c for c in df.columns if c.startswith("xmod_") and "tof" in c.lower()]
    xmod_thm = [c for c in df.columns if c.startswith("xmod_") and "thm" in c.lower()]

    if tof_cols:
        df.loc[drop_tof, tof_cols] = 0
        if "mod_present_tof" in df.columns:
            df.loc[drop_tof, "mod_present_tof"] = 0
        if xmod_tof:
            df.loc[drop_tof, xmod_tof] = 0
    if thm_cols:
        df.loc[drop_thm, thm_cols] = 0
        if "mod_present_thm" in df.columns:
            df.loc[drop_thm, "mod_present_thm"] = 0
        if xmod_thm:
            df.loc[drop_thm, xmod_thm] = 0
    return df
```

---

### 6-6. PyTorch RNN のパディングスキップ（概念例）

```python
# 取得時に有効長も返す
def pad_and_mask(x: np.ndarray, pad_len: int):
    T, C = x.shape
    out = np.zeros((pad_len, C), dtype=np.float32)
    msk = np.zeros((pad_len,), dtype=np.float32)
    t = min(T, pad_len)
    out[:t] = x[:t]
    msk[:t] = 1.0
    return out, msk, t

# Dataset で長さ t を返す
# collate で lengths を Tensor にまとめる

# forward 内で
x_packed = nn.utils.rnn.pack_padded_sequence(h, lengths, batch_first=True, enforce_sorted=False)
h_packed, _ = self.bilstm(x_packed)
h, _ = nn.utils.rnn.pad_packed_sequence(h_packed, batch_first=True, total_length=T_prime)
```

> 既存の downsampled mask と整合を取る場合、`lengths` も同じダウンサンプル比で除算/切り上げして合わせます。

---

### 6-7. Welch の `nperseg` を軽量化

```python
# in extract_frequency_features
nperseg = min(64, len(data)//4, len(data))
```

必要であれば `noverlap = nperseg // 2` のままで問題ありません。

---

### 6-8. LightGBM の早期終了 & サブサンプル頻度

```python
Config.LGBM_PARAMS.update({
    "subsample_freq": 1,  # bagging を各イテレーションで
})
# callbacks
early_stopping(stopping_rounds=50, verbose=True)
```

---

## 7) そのほか小さな提案

- **Keras の学習率ログ**：

  ```python
  lr_attr = getattr(self.model.optimizer, "lr", getattr(self.model.optimizer, "learning_rate", 0.0))
  lr_val = float(lr_attr.numpy()) if hasattr(lr_attr, "numpy") else float(lr_attr)
  ```

- **Torch の DataLoader**：`prefetch_factor` は `num_workers>0` のときのみ設定（すでに条件付きで OK）。
- **FeatureCache キー**：`sequence_id` が欠損する可能性がゼロでない場合に備え、`get` 失敗時の fallback を `hash pandas values` にするなどもあり（任意）。
- **テスト用クォータニオン**：ダミーの `rot_*` を標準正規で生成していますが、実運用では正規化されたクォータニオンを入れるテストの方が Euler/角速度の妥当性確認になります。

---

## まとめ

- \*\*構造の修正（実行順序 & MODEL_PATH 分岐）\*\*が最優先です。
- そのうえで、**OOF をスキップ時も作る**、**modality dropout のベクトル化**、**周波数特徴の軽量化**、**RNN のパディング計算スキップ**を入れると、**精度を保ちつつ前処理/学習時間を大きく短縮**できます。
- 既存のログ設計・再開機能・フレームキャッシュはとても良いです。上記のポイントを反映すれば、堅牢性と速度の両面でかなり扱いやすいパイプラインになります。
